<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>fzyho的小站</title>
    <link>https://fzyho.github.io/</link>
    <description>Recent content on fzyho的小站</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-ch</language>
    <lastBuildDate>Sun, 04 Dec 2022 20:14:23 +0900</lastBuildDate><atom:link href="https://fzyho.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Mock相关概念</title>
      <link>https://fzyho.github.io/docs/jmockit/mock%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5/</link>
      <pubDate>Sun, 19 Jan 2020 21:04:11 +0900</pubDate>
      
      <guid>https://fzyho.github.io/docs/jmockit/mock%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5/</guid>
      <description>在讲解JMockit的使用之前，笔者想先简单描述一些与Mock相关的概念和定义，以便后面更好的进行讲解叙述。
Test Doubles 在自动化测试或者进行单元测试中，我们常常希望能够将某个模块隔离解耦出来，单独地进行测试。如此我们可以降低测试用例构建的难度和复杂度，并且无需担心测试的模块会受到系统其他模块的影响。为此，我们就需要构建一些行为与实际生产环境类似的简化的对象。Gerard Meszaros在其著作《xUnit Test Patterns: Refactoring Test Code》将此类对象用一个概括性的通用术语表示——Test Doubles(此术语源于stunt double，特技替身演员)：
When we are writing a test in which we cannot (or chose not to) use a real depended-on component (DOC), we can replace it with a Test Double. The Test Double doesn&amp;rsquo;t have to behave exactly like the real DOC; it merely has to provide the same API as the real one so that the SUT thinks it is the real one!</description>
    </item>
    
    <item>
      <title>流</title>
      <link>https://fzyho.github.io/docs/quic/%E6%B5%81/</link>
      <pubDate>Sun, 04 Dec 2022 20:14:23 +0900</pubDate>
      
      <guid>https://fzyho.github.io/docs/quic/%E6%B5%81/</guid>
      <description>流可以是单向(unidirection)的也可以是双向的(bidirection)。流可以通过传输数据来创建。单个STREAM帧可以创建/关闭流或者在流中传输数据。流可以在整个连接过程中存在。
每个终端节点都可以创建多个流，并且并发的向其他终端节点传输数据。
2.1 流的类型和标识符 流在连接中，通过一个Stream ID来进行标识。此ID是一个62位的整型($[0,2^{62}-1]$)，使用变长(variable-length)的整型值来来编码。QUIC节点在一个连接里，不会重用Stream ID，因此同一连接中的Stream ID是唯一的。
Stream ID的最低位(0x01)表示的是流的创建者，若是client创建的流，最低位为0；server创建的流，最低位则为1。
Stream ID的最第二低位(0x02)则用于区分双向流还是单向流。若为双向流，则设为0；单向流则设为1。
Bits Stream Type 0x00 Client-Initiated, Bidirectional 0x01 Server-Initiated, Bidirectional 0x02 Client-Initiated, Unidirectional 0x03 Server-Initiated, Unidirectional 以下这段，不大理解，但应该是要求Stream ID是递增的
The stream space for each type begins at the minimum value (0x00 through 0x03, respectively); successive streams of each type are created with numerically increasing stream IDs. A stream ID that is used out of order results in all streams of that type with lower-numbered stream IDs alsobeing opened.</description>
    </item>
    
    <item>
      <title>流状态</title>
      <link>https://fzyho.github.io/docs/quic/%E6%B5%81%E7%8A%B6%E6%80%81/</link>
      <pubDate>Sun, 04 Dec 2022 20:14:23 +0900</pubDate>
      
      <guid>https://fzyho.github.io/docs/quic/%E6%B5%81%E7%8A%B6%E6%80%81/</guid>
      <description>本节从发送方/接收方的角度来对流进行讲解。单向流中根据流的类型和终端角色的不同，可能是发送端也可能是接收端。而双向流的中的两终端既可以是发送端也可以是接收端。
大多数情况下，发送端和接收端的情况都是一样的。但在打开流(open stream)的情况中，双向流会稍微复杂些，因为无论是发送还是接收端的打开，都会需要完成流的双向打开。
此文档使用流状态(stream state) 来描述：何时以及如何发送不同类型的帧的规则，以及接收不同类型帧时预期的反应。实现上，可以定义多种端角色(不只是发送/接收端)，只需要保证流状态的实现与要求一致。
Note: 此处的发送/接收端，不是指具体的一个应用/实例端，而是流的发送/接收部分
1、发送端流状态 发送端的状态转换如下表所示
o | Create Stream (Sending) | Peer Creates Bidirectional Stream v +-------+ | Ready | Send RESET_STREAM | |----------------------. +-------+ | | | | Send STREAM / | | STREAM_DATA_BLOCKED | v | +-------+ | | Send | Send RESET_STREAM | | |---------------------&amp;gt;| +-------+ | | | | Send STREAM + FIN | v v +-------+ +-------+ | Data | Send RESET_STREAM | Reset | | Sent |------------------&amp;gt;| Sent | +-------+ +-------+ | | |Recv All ACK | Recv ACK v v +-------+ +-------+ | Data | | Reset | | Recvd | | Recvd | +-------+ +-------+ Ready状态表示一个新创建的流可以从application中接收数据，在这状态中，流数据会被缓存(buffered)以准备发送。发送第一个STREAM或者STREAM_DATA_BLOCKED帧表示流的发送端进入Send状态。实现中，可以选择在发送了第一个STREAM帧并进入此状态时再分配stream ID，以便可以更好的利用流优先级。</description>
    </item>
    
    <item>
      <title>mysql的自我使用规范</title>
      <link>https://fzyho.github.io/posts/mysql%E7%9A%84%E4%BD%BF%E7%94%A8%E8%87%AA%E6%88%91%E8%A7%84%E8%8C%83/</link>
      <pubDate>Thu, 25 Aug 2022 18:01:47 +0800</pubDate>
      
      <guid>https://fzyho.github.io/posts/mysql%E7%9A%84%E4%BD%BF%E7%94%A8%E8%87%AA%E6%88%91%E8%A7%84%E8%8C%83/</guid>
      <description>以下笔者在多年后端工作中MySQL数据库使用经历的归纳总结。内容不长，要点不多，会尽量避免常识性的规范。以免以后自己回顾也没心情看下去。
以下规范是基于InnoDB的前提下写的，若为其他存储引擎，请注意参考使用。
1. 设计规范 1.1 字符集 MySQL的字符集中，utf8是3个字节长度的，因此无法真正囊括所有utf-8编码，若用其春初存储包含如：😭(哭表情)的内容时，会导致整个内容编码错乱。而utf8mb4才是最多4个字节长度，即与utf-8编码真正对应的字符集。
因此建议统一使用utf8mb4字符集存储字符串。 需要知道的是，VARCHAR(N)类型的字段，N指的是字符串长度。字节长度是编码$\times N$，对于utf8mb4来说，即$4\times N$。
1.2 主键 主键使用自增主键有个好处就是可以提高数据页的利用率，减少页空洞和分裂。
InnoDB使用的是B+树来进行数据组织，叶子结点存储的是数据页(主键索引的B+树中)。每个叶子结点都有个双向指针连接着前后叶子，构成一个双向链表。
因为数据页大小是固定的(默认为16KB)，当数据按主键递增的形式插入时，索引是紧凑的，数据页也会有序增加，页中不会出现空洞；而若数据是随机插入，则会导致数据页空洞，比如id为[4,6]的数据可以构成一个数据页，结果只插入了4、6，id=5的数据没有插入。
此处可以配置图片 此外，主键不递增还会导致页分裂，原本[10,20]的数据只有id=10,15,20三行，存放于一个数据页中，后面随机插入了剩余的id数据，导致一个数据页不足以存储，需要分裂为多个数据页(即增加数据页)。此时实际上是索引的B+树也在重新建立索引。
1.3 简化使用 禁止使用存储过程、视图、触发器、Event等工具，禁止使用外键。 MySQL擅长做存储和索引相关的工作，其他工作交由其他擅长的工具应付，比如ES、HBase，Redis等。对于高并发的大数据量业务，将计算逻辑放在数据库层，容易拖垮数据库。
1.4 分库(分)表 笔者工作至今遇到有两种分库表的形式，一种是按照userId进行分库分表，一种是按照日期(每月、每天、每时)进行分表。(p.s. 按照时间进行日志表归档某种程度上不算是分库表)。
一般认为设计实现分库表，是为了提升性能——将一张大表拆分成多张小表，这样MySQL的性能能有显著的提升。这样的认知笔者认为是不完全正确的。B+树在层数为4时，即可存放几十亿的数据，因此一般最多4次I/O的时间即可查询到相应的数据。分库表可能就把层数降低一层，性能不会有太大提升。当然，在在扫描数据量极大的范围查询中，分库表确实可以提高性能和效率。
分库表的设计更多是为了方便管理，以及数据量过大，超过一般单数据库服务器(通常为500GB)所能容纳的。
像按userId进行分库表，一般是为了方便后续数据量过大时可拓展；而按日期分表，则是为了方便管理，后续移除/清空无用数据时简单方便。
1.5 字段设计 IP相关的字段可以使用INT UNSIGNED类型存储。使用inet_aton(&amp;lsquo;255.255.255.255&amp;rsquo;)和select inet_ntoa(4294967295)进行转化。 把字段定义为NOT NULL并且提供默认值，比如0。null的列使索引/索引统计/值比较都更加复杂，对MySQL来说更难优化 1.6 索引设计 单表的索引不能过多，目前自我限制为7个，同时单个索引的字段数量不能多余3个。
设计索引时，多考虑建立联合索引，并把区分度最高的字段放在最前面。以便利用上最左匹配原则。另外还应避免出现冗余索引的情况，比如已建立了缩影key(a,b)，若再建立索引key(a)，则为索引冗余了。
WHERE中过滤条件的字段顺序无需和索引一致，但若有排序、分组则必须一致。而且排序的代价往往更高，因此若explain中有 Using filesort，应优先创建排序索引。
2. 编写规范 1.1 代码层编写规范 笔者工作至今常用的第三方SQL工具是mybatis，然后就是公司自研工具。以mybatis为例，一般常用mybatis-generator工具生成对应的DO、Mapper和xml配置。但自动生成的sql常常比较复杂，建议对于sql进行手动拼写。
SELECT语句必须指定具体字段名称，禁止写成*，并且应该带上limit，以防获取数量过多对性能造成影响。select *会将不该读取的数据也从MySQL里读出来，一方面会造成性能多余损耗，而且表字段一旦更新，但model层没有对应及时更新的话，系统会报错。
业务逻辑并发操作同一个表，可能会产生行锁甚至表锁，导致并发性能下降；因此建议更新操作的sql能统一都基于主键去更新。此外，更新操作所基于的主键/索引应该保证统一的顺序，以防死锁。
对于单表读写比大于10:1的数据行或单个列，可考虑将热点数据放在缓存中(如redis)，以加快访问速度，同时降低MySQL压力。
1.2 SQL编写规范 大表不应使用子查询(select中嵌套select)，应转为使用性能稳定的join查询。而在多表join的SQL里，保证被驱动表的连接列上有索引，这样join执行效率最高。而join表也不应过多，笔者自我要求是3个以内。
应当注意避免隐式数据类型转换，在索引字段中使用函数或逻辑运算。这些情况是会导致索引失效的。如：
1 2 3 4 5 # phone是varchar，userId是bigint，二者均为索引字段 # 但以下皆为索引失效 SELECT uid FROM t_user WHERE phone=18800000000 SELECT uid FROM t_user WHERE length(phone)=11 SELECT uid FROM t_user WHERE userId+1=2 分页查询时，当limit起点较高，可先用过滤条件进行过滤。如select a,b,c from t1 limit 1000,5优化为: select a,b,c from t1 where id&amp;gt;1000 limit 5。id为递增的主键Id。</description>
    </item>
    
    <item>
      <title>分布式系统简述 Part 3</title>
      <link>https://fzyho.github.io/posts/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%AE%80%E8%BF%B0-part-3/</link>
      <pubDate>Thu, 02 Jun 2022 23:04:15 +0800</pubDate>
      
      <guid>https://fzyho.github.io/posts/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%AE%80%E8%BF%B0-part-3/</guid>
      <description>以下是笔者阅读学习Distributed Systems: for fun and profit所做的记录，大体算是笔者对书中内容的翻译。感兴趣的可以阅读原文~
5、Replication：弱一致性模型协议 在很长一段时间里，我们都是通过一个全局全序的方法来解决一致性问题，前面已经讨论了方法，它们都是通过非自然生成的全序顺序(以一种容错的方式)的形式来实现强一致性的。当然，强制实现有序的代价是昂贵的。特别是在大型的需要维持可用性(Avaliable)的互联网系统，这基本是行不通的。一个强制实现强一致性的系统会像一个单机系统一样运行，而不是分布式系统，这将会导致它在出现分区时可用性很糟糕。
更进一步的说，对于每次操作，多数节点都要保持联系——而且经常不是一次而是两次(正如在2PC上的讨论一样)。尤其是对于在地理上分布以为全球用户提供高性能的系统来说，这是十分令人痛苦。因此默认想单机系统一样运行可能是不可取的(Not Desirable)。
可能我们想要的系统是一个不需要编写复杂的用于协调的代码，然后也能返回一个“有用的”值。我们允许不同的副本相互之间有分歧——但可以保证执行效率和分区容灾——然后尝试找到一种方法来解决分歧。
最终一致性-Eventual Consistency就表达上述的想法：节点偶尔可以相互之间存在分歧，但是它们最终能够达到一致。最终一致性可分为以下两种形式：
Eventual consistency with probabilistic guarantees 在一段时间后(at some later point)，能够检测到写冲突，但是不能保证结果与正确的顺序执行的结果一致。也就是说，冲突更新有时会用旧值覆盖新值，导致一些异常情况的发生。 Eventual consistency with strong guarantees 此类型的系统能保证最终结果与正确顺序执行的结果一致(即不会产生异常结果)。如此，在没有任何协调操作的情况下，你可以创建副本，而这些副本可以以任意的形式通信、以任意的顺序接受更新命令，并且最终它们会达成一致的结果——只要他们接受到的信息是一样的。 CRDT&amp;rsquo;s (convergent replicated data types) 这是一种数据类型，在网络延迟、分区和信息重排序的情况下也能够得到相同结果。它们具有可证明的收敛性(Convergent)，但是可以实现为CRDT类型的数据类型是有限的。 CALM (consistency as logical monotonicity)猜想 此猜想(conjecture)是同一原理的不同表达：它把逻辑单调性(Logical Monotonicity)等同于收敛性(Convergent)。如果我们能推断得出某个系统是逻辑单调的，那么它可以无需协调即可安全运行。 5.1 Reconciling different operation orders 假设系统各节点因为某些原因无法通信，每个副本在分区时仍维持可用性，从一些客户端中接受读/写操作。而一段时间后，分区问题解决了，副本服务器相互交换信息。它们从不同的客户端接受不同的更新操作，并且相互之间存在分歧。因此需要进行调解——我们希望副本最终能达至一致的结果。
[Clients] - &amp;gt; [A] --- Partition --- [Clients] - &amp;gt; [B] --- Partition --- [Clients] - &amp;gt; [C] $\qquad\qquad\Downarrow$
[A] \\ --&amp;gt; [merge] [B] // | | [C] ----[merge]---&amp;gt; result 5.</description>
    </item>
    
    <item>
      <title>分布式系统简述 Part 2</title>
      <link>https://fzyho.github.io/posts/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%AE%80%E8%BF%B0-part-2/</link>
      <pubDate>Tue, 17 May 2022 20:17:49 +0800</pubDate>
      
      <guid>https://fzyho.github.io/posts/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%AE%80%E8%BF%B0-part-2/</guid>
      <description>以下是笔者阅读学习Distributed Systems: for fun and profit所做的记录，大体算是笔者对书中内容的翻译。感兴趣的可以阅读原文~
4、Replication 复制是一系列的通信问题——怎样的分配和通信方式能够达到我们想要的性能和有效性呢？在面对网络分区和同时多点故障时，我们如何保证容灾、持久以及无分歧呢？
分配和通信模式可以分成几个阶段：
请求(Request): 客户端发送一个请求到服务器端 同步(Sync): 复制的同步部分发生 响应(Respond): 返回一个响应给客户端 异步(Async): 复制的异步部分发生 上述模式切割基于这篇文章。需要注意，此模式任务中各个部分的消息交换依赖于特定算法，这里并没有给出(故意略过)。
4.1 同步复制(Synchronous replication) 同步复制也被称为Active或者Eager或者Push或者Pessimistic Replication。
同步复制有三个阶段：发出请求，然后调用复制的同步部分(这意味着客户端阻塞知道系统返回一个结果)。 假定同步部分，我们采取一个写N-to-N的方法：在响应返回给前端之前，系统的所有服务器已然知道此响应结果。而且如此，系统则不能允许任何一个服务器端故障，若故障，则客户端的写请求将无法进行。
4.2 异步复制(Asynchronous replication) 异步复制也被称为Passive或者Pull或者Lazy Replication。异步复制，顾名思义，是和同步复制相反的——master服务器立刻返回响应给客户端，而不会做任何与其他服务器的同步导致客户端阻塞。而且同样，其与其他服务器交流使用的通信模式也是根据不同的算法而不同。
假定采取的算法叫写1-to-N方法，从性能的角度上看，这样的系统是更快的，但是它的分配方式只能提供弱或者概率持久性的保证。如果没有出错，数据最终会被复制到所有N台机器上，然而如果唯一包含这个数据的服务器故障了，那么这个数据将会永远丢失。
使用写1-to-N方法，只要有一个节点能工作，系统就是可用的(至少在理论上是这样，实际上只有一个节点的话负载将会过高)。需要强调的一点是，被动复制(Passive Replication)不能保证系统中所有节点始终处于同一状态，如果你接受多位置(location)写且不要求这些节点同步，那么将会面临数据分歧的风险。
4.3 主流复制算法综述(An overview of major replication approaches) 复制算法的分类方式有很多种，除了同步vs异步的区分外，还可以分为：
避免数据分歧(single copy system): 此类算法能“behave like a single system”。特别是当出现分区失败时，系统保证只有一个拷贝是有效的(active)，即所有副本都是一直的，这也就是一致性/共识问题(consensus problem) 有数据分歧风险的(multi-master system) 如之前Consensus Problem所说的，要达到一致性/共识，需要满足Agreement、Integrity、Termination以及Validity。互斥(Mutual exclusion)，选举(leader election)，广播以及原子广播(atomic broadcast)都是更普遍的共识问题的例子。维护单一拷贝一致性的可复制系统需要以某种方式解决共识问题。
维护单一拷贝一致性的复制算法包括：
1n messages (asynchronous primary/backup) 2n messages (synchronous primary/backup) 4n messages (2-phase commit, Multi-Paxos) 6n messages (3-phase commit, Paxos with repeated leader election) 这些算法的容错性(fault tolerance)各不相同(例如 他们所容错的类型也不同)。以上是根据对应算法一次执行所需信息交换的次数区分的。下图改编自Ryan Barret at，展示了不同选择的不同方面： 上述图表中的：一致性(consistency)、延迟(lantency)、吞吐量(throughput)、数据丢失(data loss)以及故障转移(failover)等特性确实可以追溯会两种不同的复制方法：同步复制和异步复制——当同步时，将获得较差的性能但强的保障。另外当后面谈到分区容忍和延时容忍石，2PC和**仲裁系统(Quorum System)**之间吞吐量的差异将更加明显。</description>
    </item>
    
    <item>
      <title>分布式系统简述 Part 1</title>
      <link>https://fzyho.github.io/posts/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%AE%80%E8%BF%B0-part-1/</link>
      <pubDate>Wed, 11 May 2022 21:20:31 +0800</pubDate>
      
      <guid>https://fzyho.github.io/posts/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%AE%80%E8%BF%B0-part-1/</guid>
      <description>以下是笔者阅读学习Distributed Systems: for fun and profit所做的记录，大体算是笔者对书中内容的翻译。感兴趣的可以阅读原文~
2、系统模型理论 2.1 Consensus Problem 遵循以下几点，计算机/节点可以达到数据一致性：
统一性(Agreement): Every correct process must agree on the same value. 完整性(Integrity): Every correct process decides at most one value, and if it decides some value, then it must have been proposed by some process. 终止性(Termination): All processes eventually reach a decision. 有效性(Validity): If all correct processes propose the same value V, then all correct processes decide V 一致性/共识问题是所有商业分布式系统的核心。毕竟我们希望无需处理分散的结果(如节点的数据分歧/不同意)就可以获得一个可靠且高性能的分布式系统。并且解决一致性问题的同时，也解决一些相关的、更高级的问题(如 原子广播、原子提交等)。</description>
    </item>
    
    <item>
      <title>浅析零拷贝</title>
      <link>https://fzyho.github.io/posts/%E6%B5%85%E6%9E%90%E9%9B%B6%E6%8B%B7%E8%B4%9D/</link>
      <pubDate>Sun, 06 Feb 2022 23:38:47 +0800</pubDate>
      
      <guid>https://fzyho.github.io/posts/%E6%B5%85%E6%9E%90%E9%9B%B6%E6%8B%B7%E8%B4%9D/</guid>
      <description>在Linux/Unix体系中，一切皆为文件(everything is a file)。这在Unix最初的论文《The UNIX TimeSharing System》中便有所体现。而对于文件，最常见而又频繁的操作便是读/写操作。Linux的读写操作，也就是标准的I/O接口是基于数据拷贝的方式实现的。
1、成因 一次文件读取的过程便是如下所示： 当程序调用系统方法read()时，程序便从用户态(User Space)切换到了内核态(Kernel Space)。read()调用转为了CPU指令，有CPU发起I/O请求。 请求经过DMA，最终落到对应的硬件设备(网卡、声卡、显卡、磁盘等)上。 数据经过各设备的缓存/缓冲区的拷贝，最终回到程序用户态，由read()方法返回。 图中的DMA，即Directlyu Mememory Access，也就是绕开CPU直接访问内存的设备。DMA分担了CPU部分功能，若没有DMA，两步缓存区数据拷贝的过程就会在CPU中进行，占用了CPU的资源。
而一次普通的网络文件传输过程则为：
从磁盘到程序的读过程即是前面所述的一次文件读取过程，而从程序到网卡则为一次文件写入过程，两个过程经历的I/O和状态变换基本是一致的，都是经历了2次状态切换、1次DMA拷贝、1次CPU拷贝
由此可以看出，Linux/Unix的标准I/O在通过中间缓存来减少磁盘I/O操作的同时，也导致了多次数据拷贝以及状态切换。这也会消耗过多的CPU资源从而影响机器/传输性能。因此，为了提高I/O性能，缓解CPU压力，零拷贝的思想由此产生。零拷贝其实并不是真的做到“0”拷贝，而是一种思想——希望尽可能的减少数据拷贝操作以减轻CPU的压力。
2、零拷贝的方式 由上面的描述可以看出，需要做的就是减少数据拷贝和状态切换次数，降低CPU负担。
2.1 mmap(内存映射文件) mmap是Linux提供的内存映射文件机制。它能内核中读缓冲区的地址和用户态下的缓冲区地址进行映射，从而实现内核缓冲区和用户缓冲区共享。如此，使用mmap代替read()方法便可以减少一次用户态到内核态之间的CPU拷贝。
mmap存在一个问题，就是多进程同时操作统一文件时，会触发SIGBUS信号，SIGBUS会杀死进程并产生coredump。这可能就会导致重要的服务经常被异常终止。因此通常我们会在使用文件前，先对文件申请锁，其他进程操作文件时，内核会发出中断信号，使得操作可以及时返回，避免进程被杀死。
2.2 sendfile mmap的方式减少了一次拷贝，但是状态切换次数并没有减少。而Linux内核2.1开始引用的sendfile系统调用方法，则可以减少两次状态切换。sendfile建立了两个文件之间的通道，数据可以不经过用户态缓冲区，直接在内核缓冲区与套接字文件描述符(socket)之间传输。 不过也因为没有经过用户态，应用程序无法对传输的文件数据进行修改，因此sendfile只适用于不需要用户态处理的传输逻辑。
此后，Linux内核2.4版本还对sendfile进行优化，内核缓冲区拷贝到socket缓存的不是文件数据而是文件描述符(fd)，DMA再根据socket缓存的文件描述符信息将内核缓冲区的数据拷贝至网卡。
至此，sendfile便可以省去2次状态切换和CPU拷贝，只需2次状态切换和2次DMA拷贝便可以完成整个传输过程。
但其也具有一定局限性：用户态不参与数据处理，需要DMA支持以及只能拷贝到socket套接字。
3、Java I/O的实现 Java的FileChannel类定义了TransferTo()方法，FileChannelImpl对该方法进行了实现
1 2 3 4 5 6 7 8 9 10 11 12 13 14 public long transferTo(long position, long count, WritableByteChannel target) throws IOException { // do something before... // Attempt a direct transfer, if the kernel supports it if ((n = transferToDirectly(position, icount, target)) &amp;gt;= 0) return n; // Attempt a mapped transfer, but only to trusted channel types if ((n = transferToTrustedChannel(position, icount, target)) &amp;gt;= 0) return n; // Slow path for untrusted targets return transferToArbitraryChannel(position, icount, target); } 在实现逻辑中，先调用transferToDirectly()方法进行文件传输，若失败(系统/内核不支持)，则选择调用transferToTrustedChannel，再失败则使用transferToArbitraryChannel()。</description>
    </item>
    
    <item>
      <title>基础概率模型</title>
      <link>https://fzyho.github.io/posts/%E5%9F%BA%E7%A1%80%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8B/</link>
      <pubDate>Sun, 14 Nov 2021 22:17:24 +0800</pubDate>
      
      <guid>https://fzyho.github.io/posts/%E5%9F%BA%E7%A1%80%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8B/</guid>
      <description>1、贝叶斯定理 $P(x|y)$是条件概率，表示在$y$事件发生的情况下，$x$事件发生的概率。故，有$P(y,x)=P(x|y)\times P(y)$，表示同时发生$x,y$事件的概率=发生$y$事件的概率 乘以 在$y$事件发生的情况下发生$x$事件的概率。
当$x,y$事件相互独立时，就有贝叶斯公式如下： $$ P(x|y)\times P(y)=P(y,x)=P(x,y)=P(y|x)\times P(x) \\ \Downarrow \\ P(x|y)=\frac {P(y|x)\times P(x) }{ P(y) } $$ 其中$P(x)$称为先验概率，$P(y|x)$称为似然率(根据观测到的结果数据来预估模型的参数)，$P(y)$称为边缘概率。而最终得出的结果$P(x|y)$则称为后验概率。
2、朴素贝叶斯 朴素贝叶斯模型是一种分类模型——给出一个事物的一些特征，推断出该事物分别属于各类类别的概率。 $$ P(c|f_1,f_2,&amp;hellip;,f_i)=P(c|f_1)\times P(c|f_2)\times &amp;hellip; \times P(c|f_i) \\ \quad \\ \Rightarrow \frac{P(f_1|c)\times P(c) }{ P(f_1) }\times \frac{P(f_2|c)\times P(c) }{ P(f_2) }\times &amp;hellip;\times \frac{P(f_i|c)\times P(c) }{ P(f_i) } $$ 在进行贝叶斯公式的乘积计算时，常常会出现结果为0——某类别没有出现过某种特征，因此当前的似然率是0。一般会采取平滑(Smoothing)的方式处理——取一个比这个数据集里最小统计概率还要小的极小值，来代替零概率.
另外，在进行概率乘积计算的过程中，当特征很多时，乘积结果可能就小到计算机无法处理的地步，因此会采用一些数学方法进行转换(比如取log，将小数转化为绝对值大于1的负数)。
2.1 朴素贝叶斯分类过程： 准备数据：收集各类别事物的实例，归纳各类别事物的特征，并将其转化为计算机所能理解的数据。这种数据也被称为训练样本。 建立模型：用计算机统计类别事物、事物特征出现的先验概率，以及在某个分类下某种特征出现的条件概率。这个过程也被称为基于样本的训练。 分类新数据：对于一个新实例的特征数据，计算机根据已经建立的模型进行推导计算，得到该实例属于每个分类的概率，实现了分类的目的。这个过程也被称为预测。 2.2 与其他分类算法的比较 和KNN 最近邻相比，朴素贝叶斯需要更多的时间进行模型的训练，但是它在对新的数据进行分类预测的时候，通常效果更好、用时更短。 和决策树相比，朴素贝叶斯并不能提供一套易于人类理解的规则，但是它可以提供决策树通常无法支持的模糊分类（一个对象可以属于多个分类）。 和SVM 支持向量机相比，朴素贝叶斯无法直接支持连续值的输入。所以，在前面的案例中，我将连续值转化成了离散值，便于朴素贝叶斯进行处理。 3、马尔可夫(Markov)假设 3.1 链式法则 链式法则是概率论中一个常用法则。它使用一系列条件概念率和边缘概率，来推导联合概率。 $$ P(x_1,x_2,&amp;hellip;,x_n)=P(x_1)\times P(x_2|x_1)\times P(x_3|x_2,x_1)\times &amp;hellip;\times P(x_n|x_1,x_2,&amp;hellip;,x_{n-1}) $$</description>
    </item>
    
    <item>
      <title>Netty浅析小记</title>
      <link>https://fzyho.github.io/posts/netty%E6%B5%85%E6%9E%90%E5%B0%8F%E8%AE%B0/</link>
      <pubDate>Mon, 18 Oct 2021 12:41:22 +0800</pubDate>
      
      <guid>https://fzyho.github.io/posts/netty%E6%B5%85%E6%9E%90%E5%B0%8F%E8%AE%B0/</guid>
      <description>Netty是使用Java编写的一个网络编程框架。直至目前，可以说Netty是Java网络编程的主流选择，其在各种业务场景，如直播、社交、游戏、电商等领域都有广泛应用。笔者在工作中也不可避免的经常与其打交道。以下便是笔者对Netty的一些特点的小记。这些特点并不是Netty独有的，只是笔者个人觉得它们或者是重要的地基，或者是有趣的设计，故而在此进行分析记录。
1、处理模型 Netty使用的是主从Reactor模型。bossGroup负责处理Accept事件，workerGroup负责处理Read/Write事件。ChannelPipeline是一个双向的链表，里面存放着各种ChannelHandler。
当收到事件，触发pipeline时，pipeline会按顺序根据事件调用ChannelHandler的相关方法。一次pipeline的所有ChannelHandler调用都是在一个eventGroup的同一个evenLoop线程中执行。由于单线程处理，不存在线程上下文切换，也无需对ChannelHandler的处理加锁，
因此纵使在海量请求处理的情况下也能保证高效的性能。但是也是由于单线程，一旦某个ChannelHandler的执行出现阻塞，所在的evenLoop线程的所有pipeline事件处理都会被卡住。因此，在实际的使用场景中，eventLoop应该只做事件消息相关操作(比如编/解码，加/解密等)，业务相关的逻辑在额外的业务线程池中进行处理。这也就是许多高性能的分布式框架(比如Dubbo Kafka等)都会使用的三层处理模型。
2、内存优化 Netty作为一款高性能的网络编程框架，能承受千万甚至上亿的流量挑战，也体现出了其内部的优秀的内存管理和优化设计。
2.1 单例与@Sharable 当客户端与服务器建立起一个连接，便会在Netty中生成一个包含连接信息的Channel对象。每个Channel都有自己的ChannelPipeline，而每个ChannelPipeline也都有持有着一系列的ChannelHandler。
因此当有大量连接建立时，服务端便会持有大量的ChannelHandler；当连接频繁建立、断开时，JVM的新生代也可能会因内存不足而频繁GC。因此对于ChannelHandler应该要尽量做到复用。对于一些无状态的ChannelHandler，Netty提供了@Sharable注解，以表示此ChannelHandler可以被所有ChannelPipeline共享。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 @Override protected void initChannel(Channel ch) throws Exception { ch.pipeline().addLast(&amp;#34;encoder&amp;#34;, ServerMessageEncoder.INSTANCE); ch.pipeline().addLast(&amp;#34;decoder&amp;#34;, new ServerMessageDecoder(...)); ch.pipeline().addLast(&amp;#34;handler&amp;#34;, ServerMessageHandler.INSTANCE); } @Sharable class ServerMessageEncoder { public static final ServerMessageEncoder INSTANCE = new ServerMessageEncoder(); // some code ... } @Sharable class ServerMessageHandler { public static final ServerMessageHandler INSTANCE = new ServerMessageHandler(); // some code .</description>
    </item>
    
    <item>
      <title>mysql索引浅析</title>
      <link>https://fzyho.github.io/posts/mysql%E7%B4%A2%E5%BC%95%E6%B5%85%E6%9E%90/</link>
      <pubDate>Tue, 07 Sep 2021 23:01:47 +0800</pubDate>
      
      <guid>https://fzyho.github.io/posts/mysql%E7%B4%A2%E5%BC%95%E6%B5%85%E6%9E%90/</guid>
      <description>什么是索引？根据mysql官方文档的阐述：
Indexes are used to find rows with specific column values quickly. Without an index, MySQL must begin with the first row and then read through the entire table to find the relevant rows. The larger the table, the more this costs. If the table has an index for the columns in question, MySQL can quickly determine the position to seek to in the middle of the data file without having to look at all the data.</description>
    </item>
    
    <item>
      <title>动态规划回顾</title>
      <link>https://fzyho.github.io/posts/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E5%9B%9E%E9%A1%BE/</link>
      <pubDate>Tue, 29 Jun 2021 16:09:24 +0800</pubDate>
      
      <guid>https://fzyho.github.io/posts/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E5%9B%9E%E9%A1%BE/</guid>
      <description>最近打算重新复习基础逻辑方面的知识，对于一些有趣或者复杂的知识点打算较为详细地记录下来，以便后面继续回顾。此文便是出于重新理解和整理动态规划的知识点而写作的。
什么是动态规划(Dynamic Programming)？动态规划是一种思想，一种运筹决策的方法。事实上许多能用动态规划解决的问题，同样可以使用回溯(backtracking)法解决。只是回溯法的时间复杂度高，而动态规划的时间复杂度低，即效率高，但相对的空间复杂度就可能会高一些。
简化的背包问题 一般理解动态规划，我喜欢从0-1背包问题出发：一个可承重$Wkg$的背包，现将$m$个重量不等的物品放入背包中，问在不超过背包所能装载重量的前提下，怎么放物品能让背包中物品的总重量最大。
回溯法 对于上述背包问题，背包的重量只是一个限制条件，我们需要进行操作的是物品。每个物品都有放入和不放入两种选择。回溯算法的方式就是通过穷举所有放入不超重的情况，记录当中最接近极限承重$Wkg$的结果。用代码表示逻辑如下：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 public static final int BAG_LOAD_BEARING = 100; // 背包的最大承重(kg) public static int getFloorWeight(int[] itemsWeight) { if (itemsWeight.length == 0) { return 0; } return calc(0, 0, itemsWeight); } private static int calc(int itemIndex, int bagCurWeight, int[] itemsWeight) { // 达到承重极限 或者 已经对所有物品做出选择后，返回当前背包重量 if (bagCurWeight == BAG_LOAD_BEARING || itemIndex == itemsWeight.</description>
    </item>
    
    <item>
      <title>Expectations</title>
      <link>https://fzyho.github.io/docs/jmockit/usage/expectations/</link>
      <pubDate>Fri, 02 Apr 2021 17:57:05 +0800</pubDate>
      
      <guid>https://fzyho.github.io/docs/jmockit/usage/expectations/</guid>
      <description>前面我们提到Record-Replay-Verify模型，在JMockit中，Expectations{}则是用于录制(Record)。
Record(录制) 录制类/对象的调用 Expectations代码块中，可以让特定方法调用(实例方法、静态方法皆可)输出指定的结果，而不用走原本方法内部的逻辑，并且可以指定只有当输入特定(范围)的参数时，才输出特定结果。需要注意的是，Expectations只能够改写非private且非static的非构造函数的方法。如果要仿造构造方法/静态方法，可以使用MockUp。
1 2 3 4 5 6 7 8 9 10 @Test void testExample(@Mocked Example mockInstance) { new Expectations() {{ mockInstance.sayHello(1, &amp;#34;test&amp;#34;); result = &amp;#34;mocked&amp;#34;; }}; Assert.assertSame(mockInstance.sayHello(1,&amp;#34;test&amp;#34;), &amp;#34;mocked&amp;#34;); Assert.assertNotSame(mockInstance.sayHello(2,&amp;#34;test&amp;#34;), &amp;#34;mocked&amp;#34;); } 如上，在Expectations代码块中指定当sayHello方法被调用且参数为1, &amp;quot;test&amp;quot;时，直接返回结果&amp;quot;mocked&amp;quot;。而参数为其他值是，走原本的方法逻辑返回结果。
除了上述代码例子，Expectations是配合Mock实例对象(@Mocked/@Injectable/@Capturing)进行录制的。Mock对象是对方法和字段都进行mock了。但某些情况我们需要使用真实的实例，但只需要对部分方法进行结果返回修改。此时可以使用Expectations(Object... )构造函数，指定对象修改其方法。
如下代码例子，向Expectations()构造函数中传入参数Example实例对象example1以及OtherExample类，并改写sayHello()方法。可以看到Example对象的sayHello方法分别返回了不同的值，而OtherExample对象的sayHello方法则返回相同结果。另外，Expectations构造函数传入的参数并没有example2，但Expectations代码块中有Mockexample2的实例方法，并且也生效了。这是因为构造函数参数只会区分是是类定义还是类实例，若是类定义则会整个类方法生效，若是类实例，则只会对代码块中mock的实例方法生效。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 @Test public void testExample2() { Example example1 = new Example(); Example example2 = new Example(); OtherExample otherExample1 = new OtherExample(); OtherExample otherExample2 = new OtherExample(); new Expectations(example1, OtherExample.</description>
    </item>
    
    <item>
      <title>Verifications</title>
      <link>https://fzyho.github.io/docs/jmockit/usage/verifications/</link>
      <pubDate>Fri, 02 Apr 2021 17:57:05 +0800</pubDate>
      
      <guid>https://fzyho.github.io/docs/jmockit/usage/verifications/</guid>
      <description>Verifications Verifications{}代码块可用于验证Mock对象调用某个方法的情况是否符合预期——调用了多少次，调用该方法调用的参数是否符合预期。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 @Test public void testExample(@Injectable VerificationExample example) { example.voidMethod(); example.voidMethod(); example.stringReturningMethod() new Verifications() {{ // 没有设定次数时，默认需要调用至少一次 example.voidMethod(); // 1 to 5 invocations are expected: example.stringReturningMethod(); minTimes = 1; maxTimes = 5; result=&amp;#34;Injectable...&amp;#34;; }}; } Verifications类只有公开的一个无参的构造函数，因此只能对@Injectable、@Mocked等Mock出来的类/对象进行验证，而不能像Expectations那样通过传参来进行指定对象方法的验证。不过在实际的程序测试中，我们对于类的某个方法有没调用，调用多少次的测试场景并不是太多；一般都可以通过Assert的方式对程序结果进行验证。
Verifications有三个子类VerificationsInOrder，FullVerifications以及二者的结合FullVerificationsInOrder。
VerificationsInOrder和Verification是相似的，但是加上了方法调用顺序的验证。如下如果在voidMethod方法调用之前调用stringReturningMethod，程序运行就会抛出异常——在调用stringReturningMethod之前Missing invocation(缺少依赖的方法调用)。 如果需要验证有且仅有Verifications()代码块中的仿造对象方法有被调用到，可以使用new FullVerifications() {&amp;hellip;}。如下如果FullVerifications代码块中注释掉example.voidMethod();，程序也会运行失败。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 @Test public void testExample(@Injectable VerificationExample example) { example.</description>
    </item>
    
    <item>
      <title>方法参数匹配</title>
      <link>https://fzyho.github.io/docs/jmockit/usage/%E6%96%B9%E6%B3%95%E5%8F%82%E6%95%B0%E5%8C%B9%E9%85%8D/</link>
      <pubDate>Fri, 02 Apr 2021 17:57:05 +0800</pubDate>
      
      <guid>https://fzyho.github.io/docs/jmockit/usage/%E6%96%B9%E6%B3%95%E5%8F%82%E6%95%B0%E5%8C%B9%E9%85%8D/</guid>
      <description>Verifications </description>
    </item>
    
    <item>
      <title>从CLH锁聊聊AQS的设计</title>
      <link>https://fzyho.github.io/posts/%E4%BB%8Eclh%E9%94%81%E8%81%8A%E8%81%8Aaqs%E7%9A%84%E8%AE%BE%E8%AE%A1/</link>
      <pubDate>Mon, 08 Feb 2021 14:16:15 +0800</pubDate>
      
      <guid>https://fzyho.github.io/posts/%E4%BB%8Eclh%E9%94%81%E8%81%8A%E8%81%8Aaqs%E7%9A%84%E8%AE%BE%E8%AE%A1/</guid>
      <description>AbstractQueuedSynchronizer，即AQS，是Java并发工具包(JUC)中的锁和同步器(Semophore、CountDownLatch等)的基础。它提供了一个上锁、释放以及锁等待的整体流程框架。AQS是基于一个FIFO的等待队列实现的，它是CLH队列锁(CLH Queuing Lock)的一种变体。因此，秉着从简到深的想法，我们先来了解下CLH队列锁。
1、CLH Lock 1.1 CLH队列锁是什么 CLH队列锁是一种自旋锁。正如名字所描述的，是一种基于队列\链表，通过将线程组织成一个队列的形式来一次进行上锁-处理-释放的同步方式。
在队列中，每个线程通过检测其前驱线程是否已完成(获得并释放锁)来判断是否轮到自己。每个线程在不同的存储单元自旋，从而降低cache一致性流，并提高临界区利用率。最后队列FIFO的特性保证了公平性。
1.2 CLH队列锁工作原理 一开始，CLHLock的队列只有一个尾部节点。然后多线程同时竞争上锁，两线程会调用原子的GetAndSet方法，获取尾部节点，并将此节点设置为自己的前驱节点作为，然后将自己线程转成节点插入队列的尾部。完成这些操作后，便进入自旋状态，直到前驱节点释放锁，即字段locked为false。
如下图，可以看作线程A、B同时竞争获取锁。线程A先插入到队尾并获得锁，线程B在线程A后面，即A是B的前驱节点。线程B会不断自旋，直到前驱结点，即线程A，的状态从locked变为unlock；而后线程B获得锁，线程A从队列中移除。
2、队列同步器(AQS) 2.1 AQS简述 AQS是基于CLHLock的一个拓展实现。其核心思想是：若被请求的资源空闲，则将当前请求资源的线程设为有限线程，并且将资源状态设为锁定。若被请求的资源被占用，则将暂时获得不到锁的线程加入队列中，并将线程挂起(阻塞)等待以及被唤醒时所分配。
AQS实现的CLHLock是一个双向队列。AQS将每条请求共享资源的线程封装成一个CLHLock队列的节点(Node)来实现所分配，并使用字段waitStatus来表示资源获得的状态。Node的类定义如下
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 static final class Node { // 表示线程取消等待，不竞争资源的获取 static final int CANCELLED = 1; // 表示获得资源锁了，对应线程无需挂起，需要唤醒 static final int SIGNAL = -1; // 用于表示线程节点在做条件等待 static final int CONDITION = -2; // 表示后续线程/节点在调用acquireShare()方法时可以无条件获得锁 static final int PROPAGATE = -3; // 初始化为0，而后或为上述4中状态值。 volatile int waitStatus; // 前驱节点 volatile Node prev; // 后继节点 volatile Node next; // 节点所代表的线程 volatile Thread thread; // 条件队列所用，表示同一条件等待队列中的下一个等待节点 Node nextWaiter; } 2.</description>
    </item>
    
    <item>
      <title>从Shuffle到Sample——谈谈基本的随机算法</title>
      <link>https://fzyho.github.io/posts/%E4%BB%8Eshuffle%E5%88%B0sample%E8%B0%88%E8%B0%88%E5%9F%BA%E6%9C%AC%E7%9A%84%E9%9A%8F%E6%9C%BA%E7%AE%97%E6%B3%95/</link>
      <pubDate>Sun, 04 Oct 2020 12:40:47 +0800</pubDate>
      
      <guid>https://fzyho.github.io/posts/%E4%BB%8Eshuffle%E5%88%B0sample%E8%B0%88%E8%B0%88%E5%9F%BA%E6%9C%AC%E7%9A%84%E9%9A%8F%E6%9C%BA%E7%AE%97%E6%B3%95/</guid>
      <description>在笔者日常的工作中，常常会碰到类似这样的功能需求：从奖励池(含有$n$种奖励)中随机$m$种给用户，其中$n&amp;gt;m$。
p.s. 笔者的工作语言是Java，因此下面的代码都是以java的方式展现的。
1. 乱序(Shuffle) 最直接的做法可能就是，将该$n$种奖励随机打乱后，选取前$m$种给玩家，即：
1 2 3 4 5 List&amp;lt;Integer&amp;gt; randomPrizeIds(List&amp;lt;Integer&amp;gt; allPrizeIds, int num) { List&amp;lt;Integer&amp;gt; copy = new ArraysList(allPrizeIds); Collections.shuffle(copy); // 打乱列表元素原本的排列顺序 return copy.subList(0, num); } 但如此做法是否真的足够随机？这就取决于shuffle函数的具体实现逻辑。
1.1 等概率论证 要足够随机，则要求shuffle乱序过程中，每个元素重排到各个位置的概率是相等的。Collections.Shuffle使用的是Knuth-Durstenfeld Shuffle算法(或说Fisher–Yates Shuffle算法)，方法内部实现逻辑大致如下：
1 2 3 4 5 6 void shuffle(List&amp;lt;?&amp;gt; list, Random rnd) { int size = list.size(); for (int i = size; i &amp;gt; 1; i--) { swap(list, i - 1, rnd.nextInt(i)); } } 其乱序的实现方式其实就是：从后往前将列表中的元素置换到首位到当前位置的任意下标位置。假定一个包含n个元素的列表，那么从后往前：
对于n-1位置，每个可选择的元素置换到此位置的概率均为$\frac{1}{n}$，则留在到$[0,n-2]$下标位置的概率为$\frac{n-1}{n}$； 对于n-2位置，每个可选择的元素置换到此位置的概率均为$\frac{n-1}{n}\cdot\frac{1}{n-1}=\frac{1}{n}$，则留在到$[0,n-3]$区间的概率为$\frac{n-1}{n-2}$。 对于n-3位置，每个可选择的元素置换到此位置的概率均为$\frac{n-1}{n}\cdot\frac{n-2}{n-1}\cdot\frac{1}{n-2}=\frac{1}{n}$，则留在到$[0,n-4]$区间的概率为$\frac{n-1}{n-2}$。 &amp;hellip;&amp;hellip;.</description>
    </item>
    
    <item>
      <title>MockUp</title>
      <link>https://fzyho.github.io/docs/jmockit/usage/mockup/</link>
      <pubDate>Sun, 19 Jan 2020 21:04:11 +0900</pubDate>
      
      <guid>https://fzyho.github.io/docs/jmockit/usage/mockup/</guid>
      <description>使用方式 MockUp的使用类似于@Mocked注解以及Expectations()的结合，但是更加直接和具体。MockUp常常需要搭配@Mock注解来使用：MockUp用于表明要Mock一个类，然后@Mock类似于@Override一般覆盖原有的方法。
MockUp可以用在类定义的时候：
1 class MockUpExample extends MockUp&amp;lt;Example&amp;gt; {...} 也可以当做是匿名类使用:
1 MockUp&amp;lt;Example&amp;gt;() {...} 当使用了MockUp构建的虚假类后(不论是定义好的类，还是测试方法内的内部类)时——比如new出对象——使用@Mock标注的方法就会替换掉对应的原本的方法，而没有被替换的就保持不变。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 @Test public void testMockUp() { MockUpThing thing = new MockUpThing(); Assert.assertSame(thing.doSomething(),&amp;#34;something&amp;#34;); new MockUp&amp;lt;MockUpThing&amp;gt;(MockUpThing.class) { @Mock String doSomething() { return &amp;#34;mock...&amp;#34;; } }; Assert.assertSame(thing.doSomething(), &amp;#34;mock...&amp;#34;); } private static class MockUpThing { String doSomething() { return &amp;#34;something&amp;#34;; } } @Mock使用范围 @Mock可以修饰final、static、native方法，不论是否方法的访问权限是否public。@Mock还可以用于修饰$init()、$cinit()来替换构造方法以及类初始化方法。显然$init()带入不同参数可以匹配不同的构造方法。而类初始化方法会替换包括所有static{.</description>
    </item>
    
    <item>
      <title>Mock注解</title>
      <link>https://fzyho.github.io/docs/jmockit/usage/mock%E6%B3%A8%E8%A7%A3/</link>
      <pubDate>Sun, 19 Jan 2020 21:04:11 +0900</pubDate>
      
      <guid>https://fzyho.github.io/docs/jmockit/usage/mock%E6%B3%A8%E8%A7%A3/</guid>
      <description>可对类或实例实现mock的注解有三种：@Mocked、@Injectable、@Capturing。通常，@Injectable是最常用的，@Mocked比较少用，@Capturing更少。如果要Mock类静态方法或其他一些行为，之后讲到的Mock、MockUp也许会更强大一些。
@Mocked注解 @Mocked用于修饰类，告诉Jmockit为该类生成一个Mocked对象。@Mocked注解会影响到该类的所有方法(包括静态方法)，但是仅限于该类自身，其往下的子类或者往上的父类的方法不会被Mocked。而Mocked的方法都会返回确定的默认值：
基础类型值(int、short、long等)返回0； String类型返回null； 引用类型则返回该类型的一个Mocked对象，并对其方法和字段递归Mocked下去。 由于@Mocked会影响到整个类，因此此注解使用起来并不灵活，用处不大，但是对于一些简单的只需要用到某个方法的返回结果而进行Mock的，使用@Mocked会直接简单许多。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 public class MockedTest { @Mocked private LocalDate date1; @Mocked private IMockedThing thing; @Test public void testMocked(@Mocked LocalDate date2) { // @Mocked作用的两个字段 指向是不同的对象 Assert.assertNotSame(date1, date2); // date1对象或者new出来的对象的 getDayOfMonth() // 结果都为0，即@Mocked作用于类而不是实例对象 Assert.assertEquals(0, date1.</description>
    </item>
    
  </channel>
</rss>
