<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>多线程 on fzyho的小站</title>
    <link>https://fzyho.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/</link>
    <description>Recent content in 多线程 on fzyho的小站</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-ch</language>
    <lastBuildDate>Sat, 21 Nov 2020 20:51:47 +0800</lastBuildDate><atom:link href="https://fzyho.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>读书笔记-The Art Of Multiprocessor Programing(四)</title>
      <link>https://fzyho.github.io/posts/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-theartofmultiprocessorprograming%E5%9B%9B/</link>
      <pubDate>Sat, 21 Nov 2020 20:51:47 +0800</pubDate>
      
      <guid>https://fzyho.github.io/posts/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-theartofmultiprocessorprograming%E5%9B%9B/</guid>
      <description>异步执行、调度和工作分配 1、 2、工作分配 工作分配的一种简单办法就是工作交易(working dealing)：一个超负荷的任务尝试着将任务分给其他的轻负荷的线程来减轻负担。这种做法有一个致命的缺点就是：如果大多数线程都是超负荷的，那么它们将会将时间浪费在交换线程的无用尝试中。因此，我们考虑工作窃取(work stealing)：一个无法工作的线程(空闲)尝试从其他线程中窃取工作。工作窃取的优点之一就是，如果所有的线程都处于忙碌状态，那么他们不必浪费事件去分配任务。
1、工作窃取 每个线程以双端队列(double-ended queue)的形式维护一个等待执行的任务池，该队列提供pushBottom()、popBottom()、popTop()方法(不需要pushTop())。当线程创建一个新任务时，调用pushBottom()方法；当线程需要执行一个任务时，调用popBottom()。而当线程发现它的任务队列为空时，它就变成了一个窃取者：随机选取一个牺牲者(victim)线程，并调用该线程任务队列的popTop()方法窃取任务。 如下是工作窃取的一种简单实现，所有工作线程共享一个DEQueue数组，每个DEQueue对应一个线程。为简化逻辑，这里忽略了窃取时触发异常的可能性。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 class WorkStealingThread { DEQueue[] queue; int me; Random random; WorkStealingThread(DEQueue[] queue) { this.queue = queue; this.random = new Random(); } void run() { int me = ThreadID.get(); Runnable task = queue[me].popBottom(); // pop first task while (true) { while (task !</description>
    </item>
    
    <item>
      <title>读书笔记-The Art Of Multiprocessor Programing(三)</title>
      <link>https://fzyho.github.io/posts/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-theartofmultiprocessorprograming%E4%B8%89/</link>
      <pubDate>Tue, 11 Aug 2020 13:12:47 +0800</pubDate>
      
      <guid>https://fzyho.github.io/posts/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-theartofmultiprocessorprograming%E4%B8%89/</guid>
      <description>并行队列与ABA问题 1、池的定义与形式 池，即为存放东西的一个容器，的作用往往与生产者——消费者缓冲区的作用相同。 池有以下几种不同的变化形式：
池可以是有界或无界的。有界池存放有限个元素，而无限池可以存放任意数量的元素。当需要保持生产者与消费者之间的松弛同步，即生产者不要过快超过消费者时，就要用到有界池。有界池的实现可能要比无限池简单(==并不觉得，反而感觉恰恰相反==)，当不用设定固定的界限来限制生产者与消费者之间的速率时，可以使用无限池。 池的方法可以是完全、部分或者同步的 完全(Total)： 若一个方法的调用不需要等待某个条件成立，则该方法时完全的。例如，一个试图从空池中删除元素的get()调用 或者 往满池中添加元素的set()调用将立刻返回错误码或者抛出一个异常。 部分(Partial)： 若一个方法的调用****需要**等待某个条件成立，则该方法是部分的。例如，空池中删除元素/满池中插入元素 将会阻塞直到满足条件。 同步(synchronous)： 若一个方法需要等待另一个方法与它的调用间隔相重叠，则称该方法是同步的。例如，在一个同步池中，一个向池中添加元素的方法将会被阻塞直到该添加的元素被取走。同样删除元素的调用也会被阻塞直到有元素被添加为止(此方法同时也是部分的)。 2、部分有界队列(An Bounded Partial Queue) 队列本身包含Head和Tail字段。与第九章的链表一样，此处Head和Tail充当哨兵节点——其值是无意义的。而不同的是，第九章的哨兵节点是固定不变的，而这里的队列则是不断地更换哨兵节点。对于enq()和deq()方法，分别使用不同的锁，由此保证入队不会锁住出队。 对于唤醒丢失(lost-wakeup)问题，由于在await之前，已获得condition对应的锁，保证await之前其他线程无法signal，故没有唤醒丢失问题。 有一点需要注意的就是——由于并发操作，Head和Tail字段不一定始终指向头/尾节点。
另外此实现有一个缺点就是并发的enq()和deq()互相干扰，所有方法对size字段调用的getAndIncrement或getAndDecreament比一般的读写开销更大，且能引起顺序瓶颈*==并不明白这话什么意思==* 可以通过将size分成两个计数器——enqSideSize和deqSideSize，enq增1，deq减1。enq()检测enqSideSize&amp;lt;capacity则继续执行；若enqSideSize==capacity则锁住deqLock并将deqSideSize加到enqSideSize中。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 class BoundedQueue&amp;lt;T&amp;gt; { private final int capacity; private AtomicInteger size; private volatile Node head, tail; private final ReentrantLock enqLock, deqLock; private final Condition notEmptyCondition, notFullCondition; BoundedQueue(int capacity) { this.</description>
    </item>
    
    <item>
      <title>读书笔记-The Art Of Multiprocessor Programing(二)</title>
      <link>https://fzyho.github.io/posts/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-theartofmultiprocessorprograming%E4%BA%8C/</link>
      <pubDate>Wed, 13 May 2020 21:34:47 +0800</pubDate>
      
      <guid>https://fzyho.github.io/posts/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-theartofmultiprocessorprograming%E4%BA%8C/</guid>
      <description>链表: 锁的作用 1、锁的类型 粗粒度锁：简单地将逻辑的顺序实现的代码块锁住。 细粒度锁：不再使用单一的锁来解决每次对象存取的同步，而是将对象分解成一些独立的同步组件，并确保只有当多个方法调用试图同时访问同一组件时才发生冲突 乐观同步：在查找时无需获取任何锁，如果找到所需要的部分，则锁住该组件，然后确认组件在被检测和上锁期间没有发生变化。这种方式只在成功次数高于失败次数时才具有价值，故称为乐观。常用于树、链表等数据结构中 惰性同步：有时将较难的工作推迟完成是一种好的处理方式。例如，从一个数据结构中删除某个部分的数据可以分成两个阶段——通过设置标志位来逻辑删除此部分，然后再通过数据结构卸载这部分来物理删除它。 非阻塞同步：完全消除锁，利用类似于compareAndSet()的内置原子操作来进行同步。 2、链表的并发推理 3、粗粒度同步 粗粒度锁最大的优点就是显而易见的正确性。所有方法只有在获取锁后才能对链表进行操作，所以执行顺序必定是串行的。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 class CoarseList&amp;lt;T&amp;gt; { private Node&amp;lt;T&amp;gt; head; private Lock lock = new ReentrantLock(); CoarseList() { head = new Node&amp;lt;&amp;gt;(Integer.</description>
    </item>
    
    <item>
      <title>读书笔记-The Art Of Multiprocessor Programing(一)</title>
      <link>https://fzyho.github.io/posts/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-theartofmultiprocessorprograming%E4%B8%80/</link>
      <pubDate>Tue, 07 Apr 2020 23:11:47 +0800</pubDate>
      
      <guid>https://fzyho.github.io/posts/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-theartofmultiprocessorprograming%E4%B8%80/</guid>
      <description>自旋锁与争用 1、测试-设置(Test-And-Set) 如下图所示，是两个无死锁互斥的自旋锁实现。理论上TASLock和TTASLock算法应该没什么不同。但是实际上随着线程数的增加，线程争用锁愈发频繁。TTASLock的性能会比TASLock好上许多。
class SpinLock implements Lock {AtomicBoolean state = new AtomicBoolean(false);// TASLock算法void lock() {while (state.getAndSet(true)) {}}// TTASLock算法void lock() {while (true) {while (state.get()) {};if (!state.getAndSet(true)) {return;}}}void unlock() {state.set(false);}} 原因在于state.getAndSet()语句本质上是总线上的一个广播(volatile原因)，因而会延迟所有线程(线程必须通过总线才能和内存通信，而每个时刻只能有一个处理器或存储控制器访问总线)。TTASLock的state.get()判断一直循环，没有往下走，即 所在的线程一直本地旋转，没有产生总线流量(bus traffic)。
本地旋转指线程反复地读取cache的值而不是访问总线。这一概念是设计高效自旋锁的一个重要的原则。
2、指数后退(Exponential Backoff) 当大量线程争用锁时(高争用)，那么纵然时TTASLock也会产生过多的总线流量——一个线程unlock后，会导致大量(甚至所有)争用的线程都去执行state.getAndSet()方法。因此可以通过backoff的方式回避这种情况。
class BackoffLock implements Lock {private AtomicBoolean state = new AtomicBoolean(false);private static final int MIN_DELAY = .</description>
    </item>
    
  </channel>
</rss>
