<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>算法 on Lzero的小站</title>
    <link>https://fzyho.github.io/tags/%E7%AE%97%E6%B3%95/</link>
    <description>Recent content in 算法 on Lzero的小站</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-ch</language>
    <lastBuildDate>Thu, 02 Jun 2022 23:04:15 +0800</lastBuildDate><atom:link href="https://fzyho.github.io/tags/%E7%AE%97%E6%B3%95/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>分布式系统简述 Part 3</title>
      <link>https://fzyho.github.io/posts/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%AE%80%E8%BF%B0-part-3/</link>
      <pubDate>Thu, 02 Jun 2022 23:04:15 +0800</pubDate>
      
      <guid>https://fzyho.github.io/posts/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%AE%80%E8%BF%B0-part-3/</guid>
      <description>以下是笔者阅读学习Distributed Systems: for fun and profit所做的记录，大体算是笔者对书中内容的翻译。感兴趣的可以阅读原文~
5、Replication：弱一致性模型协议 在很长一段时间里，我们都是通过一个全局全序的方法来解决一致性问题，前面已经讨论了方法，它们都是通过非自然生成的全序顺序(以一种容错的方式)的形式来实现强一致性的。当然，强制实现有序的代价是昂贵的。特别是在大型的需要维持可用性(Avaliable)的互联网系统，这基本是行不通的。一个强制实现强一致性的系统会像一个单机系统一样运行，而不是分布式系统，这将会导致它在出现分区时可用性很糟糕。
更进一步的说，对于每次操作，多数节点都要保持联系——而且经常不是一次而是两次(正如在2PC上的讨论一样)。尤其是对于在地理上分布以为全球用户提供高性能的系统来说，这是十分令人痛苦。因此默认想单机系统一样运行可能是不可取的(Not Desirable)。
可能我们想要的系统是一个不需要编写复杂的用于协调的代码，然后也能返回一个“有用的”值。我们允许不同的副本相互之间有分歧——但可以保证执行效率和分区容灾——然后尝试找到一种方法来解决分歧。
最终一致性-Eventual Consistency就表达上述的想法：节点偶尔可以相互之间存在分歧，但是它们最终能够达到一致。最终一致性可分为以下两种形式：
Eventual consistency with probabilistic guarantees 在一段时间后(at some later point)，能够检测到写冲突，但是不能保证结果与正确的顺序执行的结果一致。也就是说，冲突更新有时会用旧值覆盖新值，导致一些异常情况的发生。 Eventual consistency with strong guarantees 此类型的系统能保证最终结果与正确顺序执行的结果一致(即不会产生异常结果)。如此，在没有任何协调操作的情况下，你可以创建副本，而这些副本可以以任意的形式通信、以任意的顺序接受更新命令，并且最终它们会达成一致的结果——只要他们接受到的信息是一样的。 CRDT&amp;rsquo;s (convergent replicated data types) 这是一种数据类型，在网络延迟、分区和信息重排序的情况下也能够得到相同结果。它们具有可证明的收敛性(Convergent)，但是可以实现为CRDT类型的数据类型是有限的。 CALM (consistency as logical monotonicity)猜想 此猜想(conjecture)是同一原理的不同表达：它把逻辑单调性(Logical Monotonicity)等同于收敛性(Convergent)。如果我们能推断得出某个系统是逻辑单调的，那么它可以无需协调即可安全运行。 5.1 Reconciling different operation orders 假设系统各节点因为某些原因无法通信，每个副本在分区时仍维持可用性，从一些客户端中接受读/写操作。而一段时间后，分区问题解决了，副本服务器相互交换信息。它们从不同的客户端接受不同的更新操作，并且相互之间存在分歧。因此需要进行调解——我们希望副本最终能达至一致的结果。
[Clients] - &amp;gt; [A] --- Partition --- [Clients] - &amp;gt; [B] --- Partition --- [Clients] - &amp;gt; [C] $\qquad\qquad\Downarrow$
[A] \\ --&amp;gt; [merge] [B] // | | [C] ----[merge]---&amp;gt; result 5.</description>
    </item>
    
    <item>
      <title>分布式系统简述 Part 2</title>
      <link>https://fzyho.github.io/posts/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%AE%80%E8%BF%B0-part-2/</link>
      <pubDate>Tue, 17 May 2022 20:17:49 +0800</pubDate>
      
      <guid>https://fzyho.github.io/posts/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%AE%80%E8%BF%B0-part-2/</guid>
      <description>以下是笔者阅读学习Distributed Systems: for fun and profit所做的记录，大体算是笔者对书中内容的翻译。感兴趣的可以阅读原文~
4、Replication 复制是一系列的通信问题——怎样的分配和通信方式能够达到我们想要的性能和有效性呢？在面对网络分区和同时多点故障时，我们如何保证容灾、持久以及无分歧呢？
分配和通信模式可以分成几个阶段：
请求(Request): 客户端发送一个请求到服务器端 同步(Sync): 复制的同步部分发生 响应(Respond): 返回一个响应给客户端 异步(Async): 复制的异步部分发生 上述模式切割基于这篇文章。需要注意，此模式任务中各个部分的消息交换依赖于特定算法，这里并没有给出(故意略过)。
4.1 同步复制(Synchronous replication) 同步复制也被称为Active或者Eager或者Push或者Pessimistic Replication。
同步复制有三个阶段：发出请求，然后调用复制的同步部分(这意味着客户端阻塞知道系统返回一个结果)。 假定同步部分，我们采取一个写N-to-N的方法：在响应返回给前端之前，系统的所有服务器已然知道此响应结果。而且如此，系统则不能允许任何一个服务器端故障，若故障，则客户端的写请求将无法进行。
4.2 异步复制(Asynchronous replication) 异步复制也被称为Passive或者Pull或者Lazy Replication。异步复制，顾名思义，是和同步复制相反的——master服务器立刻返回响应给客户端，而不会做任何与其他服务器的同步导致客户端阻塞。而且同样，其与其他服务器交流使用的通信模式也是根据不同的算法而不同。
假定采取的算法叫写1-to-N方法，从性能的角度上看，这样的系统是更快的，但是它的分配方式只能提供弱或者概率持久性的保证。如果没有出错，数据最终会被复制到所有N台机器上，然而如果唯一包含这个数据的服务器故障了，那么这个数据将会永远丢失。
使用写1-to-N方法，只要有一个节点能工作，系统就是可用的(至少在理论上是这样，实际上只有一个节点的话负载将会过高)。需要强调的一点是，被动复制(Passive Replication)不能保证系统中所有节点始终处于同一状态，如果你接受多位置(location)写且不要求这些节点同步，那么将会面临数据分歧的风险。
4.3 主流复制算法综述(An overview of major replication approaches) 复制算法的分类方式有很多种，除了同步vs异步的区分外，还可以分为：
避免数据分歧(single copy system): 此类算法能“behave like a single system”。特别是当出现分区失败时，系统保证只有一个拷贝是有效的(active)，即所有副本都是一直的，这也就是一致性/共识问题(consensus problem) 有数据分歧风险的(multi-master system) 如之前Consensus Problem所说的，要达到一致性/共识，需要满足Agreement、Integrity、Termination以及Validity。互斥(Mutual exclusion)，选举(leader election)，广播以及原子广播(atomic broadcast)都是更普遍的共识问题的例子。维护单一拷贝一致性的可复制系统需要以某种方式解决共识问题。
维护单一拷贝一致性的复制算法包括：
1n messages (asynchronous primary/backup) 2n messages (synchronous primary/backup) 4n messages (2-phase commit, Multi-Paxos) 6n messages (3-phase commit, Paxos with repeated leader election) 这些算法的容错性(fault tolerance)各不相同(例如 他们所容错的类型也不同)。以上是根据对应算法一次执行所需信息交换的次数区分的。下图改编自Ryan Barret at，展示了不同选择的不同方面： 上述图表中的：一致性(consistency)、延迟(lantency)、吞吐量(throughput)、数据丢失(data loss)以及故障转移(failover)等特性确实可以追溯会两种不同的复制方法：同步复制和异步复制——当同步时，将获得较差的性能但强的保障。另外当后面谈到分区容忍和延时容忍石，2PC和**仲裁系统(Quorum System)**之间吞吐量的差异将更加明显。</description>
    </item>
    
    <item>
      <title>分布式系统简述 Part 1</title>
      <link>https://fzyho.github.io/posts/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%AE%80%E8%BF%B0-part-1/</link>
      <pubDate>Wed, 11 May 2022 21:20:31 +0800</pubDate>
      
      <guid>https://fzyho.github.io/posts/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%AE%80%E8%BF%B0-part-1/</guid>
      <description>以下是笔者阅读学习Distributed Systems: for fun and profit所做的记录，大体算是笔者对书中内容的翻译。感兴趣的可以阅读原文~
2、系统模型理论 2.1 Consensus Problem 遵循以下几点，计算机/节点可以达到数据一致性：
统一性(Agreement): Every correct process must agree on the same value. 完整性(Integrity): Every correct process decides at most one value, and if it decides some value, then it must have been proposed by some process. 终止性(Termination): All processes eventually reach a decision. 有效性(Validity): If all correct processes propose the same value V, then all correct processes decide V 一致性/共识问题是所有商业分布式系统的核心。毕竟我们希望无需处理分散的结果(如节点的数据分歧/不同意)就可以获得一个可靠且高性能的分布式系统。并且解决一致性问题的同时，也解决一些相关的、更高级的问题(如 原子广播、原子提交等)。</description>
    </item>
    
    <item>
      <title>动态规划回顾</title>
      <link>https://fzyho.github.io/posts/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E5%9B%9E%E9%A1%BE/</link>
      <pubDate>Sun, 29 Aug 2021 16:09:24 +0800</pubDate>
      
      <guid>https://fzyho.github.io/posts/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E5%9B%9E%E9%A1%BE/</guid>
      <description>最近打算重新复习基础逻辑方面的知识，对于一些有趣或者复杂的知识点打算较为详细地记录下来，以便后面继续回顾。此文便是出于重新理解和整理动态规划的知识点而写作的。
什么是动态规划(Dynamic Programming)？动态规划是一种思想，一种运筹决策的方法。事实上许多能用动态规划解决的问题，同样可以使用回溯(backtracking)法解决。只是回溯法的时间复杂度高，而动态规划的时间复杂度低，即效率高，但相对的空间复杂度就可能会高一些。
简化的背包问题 一般理解动态规划，我喜欢从0-1背包问题出发：一个可承重$Wkg$的背包，现将$m$个重量不等的物品放入背包中，问在不超过背包所能装载重量的前提下，怎么放物品能让背包中物品的总重量最大。
回溯法 对于上述背包问题，背包的重量只是一个限制条件，我们需要进行操作的是物品。每个物品都有放入和不放入两种选择。回溯算法的方式就是通过穷举所有放入不超重的情况，记录当中最接近极限承重$Wkg$的结果。用代码表示逻辑如下：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 public static final int BAG_LOAD_BEARING = 100; // 背包的最大承重(kg) public static int getFloorWeight(int[] itemsWeight) { if (itemsWeight.length == 0) { return 0; } return calc(0, 0, itemsWeight); } private static int calc(int itemIndex, int bagCurWeight, int[] itemsWeight) { // 达到承重极限 或者 已经对所有物品做出选择后，返回当前背包重量 if (bagCurWeight == BAG_LOAD_BEARING || itemIndex == itemsWeight.</description>
    </item>
    
    <item>
      <title>从Shuffle到Sample——谈谈基本的随机算法</title>
      <link>https://fzyho.github.io/posts/%E4%BB%8Eshuffle%E5%88%B0sample%E8%B0%88%E8%B0%88%E5%9F%BA%E6%9C%AC%E7%9A%84%E9%9A%8F%E6%9C%BA%E7%AE%97%E6%B3%95/</link>
      <pubDate>Thu, 04 Feb 2021 12:40:47 +0800</pubDate>
      
      <guid>https://fzyho.github.io/posts/%E4%BB%8Eshuffle%E5%88%B0sample%E8%B0%88%E8%B0%88%E5%9F%BA%E6%9C%AC%E7%9A%84%E9%9A%8F%E6%9C%BA%E7%AE%97%E6%B3%95/</guid>
      <description>在笔者日常的工作中，常常会碰到类似这样的功能需求：从奖励池(含有$n$种奖励)中随机$m$种给用户，其中$n&amp;gt;m$。
p.s. 笔者的工作语言是Java，因此下面的代码都是以java的方式展现的。
1. 乱序(Shuffle) 最直接的做法可能就是，将该$n$种奖励随机打乱后，选取前$m$种给玩家，即：
1 2 3 4 5 List&amp;lt;Integer&amp;gt; randomPrizeIds(List&amp;lt;Integer&amp;gt; allPrizeIds, int num) { List&amp;lt;Integer&amp;gt; copy = new ArraysList(allPrizeIds); Collections.shuffle(copy); // 打乱列表元素原本的排列顺序 return copy.subList(0, num); } 但如此做法是否真的足够随机？这就取决于shuffle函数的具体实现逻辑。
1.1 等概率论证 要足够随机，则要求shuffle乱序过程中，每个元素重排到各个位置的概率是相等的。Collections.Shuffle使用的是Knuth-Durstenfeld Shuffle算法(或说Fisher–Yates Shuffle算法)，方法内部实现逻辑大致如下：
1 2 3 4 5 6 void shuffle(List&amp;lt;?&amp;gt; list, Random rnd) { int size = list.size(); for (int i = size; i &amp;gt; 1; i--) { swap(list, i - 1, rnd.nextInt(i)); } } 其乱序的实现方式其实就是：从后往前将列表中的元素置换到首位到当前位置的任意下标位置。假定一个包含n个元素的列表，那么从后往前：
对于n-1位置，每个可选择的元素置换到此位置的概率均为$\frac{1}{n}$，则留在到$[0,n-2]$下标位置的概率为$\frac{n-1}{n}$； 对于n-2位置，每个可选择的元素置换到此位置的概率均为$\frac{n-1}{n}\cdot\frac{1}{n-1}=\frac{1}{n}$，则留在到$[0,n-3]$区间的概率为$\frac{n-1}{n-2}$。 对于n-3位置，每个可选择的元素置换到此位置的概率均为$\frac{n-1}{n}\cdot\frac{n-2}{n-1}\cdot\frac{1}{n-2}=\frac{1}{n}$，则留在到$[0,n-4]$区间的概率为$\frac{n-1}{n-2}$。 &amp;hellip;&amp;hellip;.</description>
    </item>
    
  </channel>
</rss>
