<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Lzero的小站</title>
    <link>http://localhost:1313/posts/</link>
    <description>Recent content in Posts on Lzero的小站</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-ch</language>
    <lastBuildDate>Tue, 06 Sep 2022 23:38:47 +0800</lastBuildDate><atom:link href="http://localhost:1313/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>浅析零拷贝</title>
      <link>http://localhost:1313/posts/%E6%B5%85%E6%9E%90%E9%9B%B6%E6%8B%B7%E8%B4%9D/</link>
      <pubDate>Tue, 06 Sep 2022 23:38:47 +0800</pubDate>
      
      <guid>http://localhost:1313/posts/%E6%B5%85%E6%9E%90%E9%9B%B6%E6%8B%B7%E8%B4%9D/</guid>
      <description>在Linux/Unix体系中，一切皆为文件(everything is a file)。这在Unix最初的论文《The UNIX TimeSharing System》中便有所体现。而对于文件，最常见而又频繁的操作便是读/写操作。Linux的读写操作，也就是标准的I/O接口是基于数据拷贝的方式实现的。
1、成因 一次文件读取的过程便是如下所示： 当程序调用系统方法read()时，程序便从用户态(User Space)切换到了内核态(Kernel Space)。read()调用转为了CPU指令，有CPU发起I/O请求。 请求经过DMA，最终落到对应的硬件设备(网卡、声卡、显卡、磁盘等)上。 数据经过各设备的缓存/缓冲区的拷贝，最终回到程序用户态，由read()方法返回。 图中的DMA，即Directlyu Mememory Access，也就是绕开CPU直接访问内存的设备。DMA分担了CPU部分功能，若没有DMA，两步缓存区数据拷贝的过程就会在CPU中进行，占用了CPU的资源。
而一次普通的网络文件传输过程则为：
从磁盘到程序的读过程即是前面所述的一次文件读取过程，而从程序到网卡则为一次文件写入过程，两个过程经历的I/O和状态变换基本是一致的，都是经历了2次状态切换、1次DMA拷贝、1次CPU拷贝
由此可以看出，Linux/Unix的标准I/O在通过中间缓存来减少磁盘I/O操作的同时，也导致了多次数据拷贝以及状态切换。这也会消耗过多的CPU资源从而影响机器/传输性能。因此，为了提高I/O性能，缓解CPU压力，零拷贝的思想由此产生。零拷贝其实并不是真的做到“0”拷贝，而是一种思想——希望尽可能的减少数据拷贝操作以减轻CPU的压力。
2、零拷贝的方式 由上面的描述可以看出，需要做的就是减少数据拷贝和状态切换次数，降低CPU负担。
2.1 mmap(内存映射文件) mmap是Linux提供的内存映射文件机制。它能内核中读缓冲区的地址和用户态下的缓冲区地址进行映射，从而实现内核缓冲区和用户缓冲区共享。如此，使用mmap代替read()方法便可以减少一次用户态到内核态之间的CPU拷贝。
mmap存在一个问题，就是多进程同时操作统一文件时，会触发SIGBUS信号，SIGBUS会杀死进程并产生coredump。这可能就会导致重要的服务经常被异常终止。因此通常我们会在使用文件前，先对文件申请锁，其他进程操作文件时，内核会发出中断信号，使得操作可以及时返回，避免进程被杀死。
2.2 sendfile mmap的方式减少了一次拷贝，但是状态切换次数并没有减少。而Linux内核2.1开始引用的sendfile系统调用方法，则可以减少两次状态切换。sendfile建立了两个文件之间的通道，数据可以不经过用户态缓冲区，直接在内核缓冲区与套接字文件描述符(socket)之间传输。 不过也因为没有经过用户态，应用程序无法对传输的文件数据进行修改，因此sendfile只适用于不需要用户态处理的传输逻辑。
此后，Linux内核2.4版本还对sendfile进行优化，内核缓冲区拷贝到socket缓存的不是文件数据而是文件描述符(fd)，DMA再根据socket缓存的文件描述符信息将内核缓冲区的数据拷贝至网卡。
至此，sendfile便可以省去2次状态切换和CPU拷贝，只需2次状态切换和2次DMA拷贝便可以完成整个传输过程。
但其也具有一定局限性：用户态不参与数据处理，需要DMA支持以及只能拷贝到socket套接字。
3、Java I/O的实现 Java的FileChannel类定义了TransferTo()方法，FileChannelImpl对该方法进行了实现
1 2 3 4 5 6 7 8 9 10 11 12 13 14 public long transferTo(long position, long count, WritableByteChannel target) throws IOException { // do something before... // Attempt a direct transfer, if the kernel supports it if ((n = transferToDirectly(position, icount, target)) &amp;gt;= 0) return n; // Attempt a mapped transfer, but only to trusted channel types if ((n = transferToTrustedChannel(position, icount, target)) &amp;gt;= 0) return n; // Slow path for untrusted targets return transferToArbitraryChannel(position, icount, target); } 在实现逻辑中，先调用transferToDirectly()方法进行文件传输，若失败(系统/内核不支持)，则选择调用transferToTrustedChannel，再失败则使用transferToArbitraryChannel()。</description>
    </item>
    
    <item>
      <title>mysql的自我使用规范</title>
      <link>http://localhost:1313/posts/mysql%E7%9A%84%E4%BD%BF%E7%94%A8%E8%87%AA%E6%88%91%E8%A7%84%E8%8C%83/</link>
      <pubDate>Mon, 25 Apr 2022 18:01:47 +0800</pubDate>
      
      <guid>http://localhost:1313/posts/mysql%E7%9A%84%E4%BD%BF%E7%94%A8%E8%87%AA%E6%88%91%E8%A7%84%E8%8C%83/</guid>
      <description>以下笔者在多年后端工作中MySQL数据库使用经历的归纳总结。内容不长，要点不多，会尽量避免常识性的规范。以免以后自己回顾也没心情看下去。
以下规范是基于InnoDB的前提下写的，若为其他存储引擎，请注意参考使用。
1. 设计规范 1.1 字符集 MySQL的字符集中，utf8是3个字节长度的，因此无法真正囊括所有utf-8编码，若用其春初存储包含如：😭(哭表情)的内容时，会导致整个内容编码错乱。而utf8mb4才是最多4个字节长度，即与utf-8编码真正对应的字符集。
因此建议统一使用utf8mb4字符集存储字符串。 需要知道的是，VARCHAR(N)类型的字段，N指的是字符串长度。字节长度是编码$\times N$，对于utf8mb4来说，即$4\times N$。
1.2 主键 主键使用自增主键有个好处就是可以提高数据页的利用率，减少页空洞和分裂。
InnoDB使用的是B+树来进行数据组织，叶子结点存储的是数据页(主键索引的B+树中)。每个叶子结点都有个双向指针连接着前后叶子，构成一个双向链表。
因为数据页大小是固定的(默认为16KB)，当数据按主键递增的形式插入时，索引是紧凑的，数据页也会有序增加，页中不会出现空洞；而若数据是随机插入，则会导致数据页空洞，比如id为[4,6]的数据可以构成一个数据页，结果只插入了4、6，id=5的数据没有插入。
此处可以配置图片 此外，主键不递增还会导致页分裂，原本[10,20]的数据只有id=10,15,20三行，存放于一个数据页中，后面随机插入了剩余的id数据，导致一个数据页不足以存储，需要分裂为多个数据页(即增加数据页)。此时实际上是索引的B+树也在重新建立索引。
1.3 简化使用 禁止使用存储过程、视图、触发器、Event等工具，禁止使用外键。 MySQL擅长做存储和索引相关的工作，其他工作交由其他擅长的工具应付，比如ES、HBase，Redis等。对于高并发的大数据量业务，将计算逻辑放在数据库层，容易拖垮数据库。
1.4 分库(分)表 笔者工作至今遇到有两种分库表的形式，一种是按照userId进行分库分表，一种是按照日期(每月、每天、每时)进行分表。(p.s. 按照时间进行日志表归档某种程度上不算是分库表)。
一般认为设计实现分库表，是为了提升性能——将一张大表拆分成多张小表，这样MySQL的性能能有显著的提升。这样的认知笔者认为是不完全正确的。B+树在层数为4时，即可存放几十亿的数据，因此一般最多4次I/O的时间即可查询到相应的数据。分库表可能就把层数降低一层，性能不会有太大提升。当然，在在扫描数据量极大的范围查询中，分库表确实可以提高性能和效率。
分库表的设计更多是为了方便管理，以及数据量过大，超过一般单数据库服务器(通常为500GB)所能容纳的。
像按userId进行分库表，一般是为了方便后续数据量过大时可拓展；而按日期分表，则是为了方便管理，后续移除/清空无用数据时简单方便。
1.5 字段设计 IP相关的字段可以使用INT UNSIGNED类型存储。使用inet_aton(&amp;lsquo;255.255.255.255&amp;rsquo;)和select inet_ntoa(4294967295)进行转化。 把字段定义为NOT NULL并且提供默认值，比如0。null的列使索引/索引统计/值比较都更加复杂，对MySQL来说更难优化 1.6 索引设计 单表的索引不能过多，目前自我限制为7个，同时单个索引的字段数量不能多余3个。
设计索引时，多考虑建立联合索引，并把区分度最高的字段放在最前面。以便利用上最左匹配原则。另外还应避免出现冗余索引的情况，比如已建立了缩影key(a,b)，若再建立索引key(a)，则为索引冗余了。
WHERE中过滤条件的字段顺序无需和索引一致，但若有排序、分组则必须一致。而且排序的代价往往更高，因此若explain中有 Using filesort，应优先创建排序索引。
2. 编写规范 1.1 代码层编写规范 笔者工作至今常用的第三方SQL工具是mybatis，然后就是公司自研工具。以mybatis为例，一般常用mybatis-generator工具生成对应的DO、Mapper和xml配置。但自动生成的sql常常比较复杂，建议对于sql进行手动拼写。
SELECT语句必须指定具体字段名称，禁止写成*，并且应该带上limit，以防获取数量过多对性能造成影响。select *会将不该读取的数据也从MySQL里读出来，一方面会造成性能多余损耗，而且表字段一旦更新，但model层没有对应及时更新的话，系统会报错。
业务逻辑并发操作同一个表，可能会产生行锁甚至表锁，导致并发性能下降；因此建议更新操作的sql能统一都基于主键去更新。此外，更新操作所基于的主键/索引应该保证统一的顺序，以防死锁。
对于单表读写比大于10:1的数据行或单个列，可考虑将热点数据放在缓存中(如redis)，以加快访问速度，同时降低MySQL压力。
1.2 SQL编写规范 大表不应使用子查询(select中嵌套select)，应转为使用性能稳定的join查询。而在多表join的SQL里，保证被驱动表的连接列上有索引，这样join执行效率最高。而join表也不应过多，笔者自我要求是3个以内。
应当注意避免隐式数据类型转换，在索引字段中使用函数或逻辑运算。这些情况是会导致索引失效的。如：
1 2 3 4 5 # phone是varchar，userId是bigint，二者均为索引字段 # 但以下皆为索引失效 SELECT uid FROM t_user WHERE phone=18800000000 SELECT uid FROM t_user WHERE length(phone)=11 SELECT uid FROM t_user WHERE userId+1=2 分页查询时，当limit起点较高，可先用过滤条件进行过滤。如select a,b,c from t1 limit 1000,5优化为: select a,b,c from t1 where id&amp;gt;1000 limit 5。id为递增的主键Id。</description>
    </item>
    
    <item>
      <title>mysql索引浅析</title>
      <link>http://localhost:1313/posts/mysql%E7%B4%A2%E5%BC%95%E6%B5%85%E6%9E%90/</link>
      <pubDate>Sat, 19 Feb 2022 23:01:47 +0800</pubDate>
      
      <guid>http://localhost:1313/posts/mysql%E7%B4%A2%E5%BC%95%E6%B5%85%E6%9E%90/</guid>
      <description>什么是索引？根据mysql官方文档的阐述：
Indexes are used to find rows with specific column values quickly. Without an index, MySQL must begin with the first row and then read through the entire table to find the relevant rows. The larger the table, the more this costs. If the table has an index for the columns in question, MySQL can quickly determine the position to seek to in the middle of the data file without having to look at all the data.</description>
    </item>
    
    <item>
      <title>从CLH锁聊聊AQS的设计</title>
      <link>http://localhost:1313/posts/%E4%BB%8Eclh%E9%94%81%E8%81%8A%E8%81%8Aaqs%E7%9A%84%E8%AE%BE%E8%AE%A1/</link>
      <pubDate>Wed, 08 Sep 2021 14:16:15 +0800</pubDate>
      
      <guid>http://localhost:1313/posts/%E4%BB%8Eclh%E9%94%81%E8%81%8A%E8%81%8Aaqs%E7%9A%84%E8%AE%BE%E8%AE%A1/</guid>
      <description>AbstractQueuedSynchronizer，即AQS，是Java并发工具包(JUC)中的锁和同步器(Semophore、CountDownLatch等)的基础。它提供了一个上锁、释放以及锁等待的整体流程框架。AQS是基于一个FIFO的等待队列实现的，它是CLH队列锁(CLH Queuing Lock)的一种变体。因此，秉着从简到深的想法，我们先来了解下CLH队列锁。
1、CLH Lock 1.1 CLH队列锁是什么 CLH队列锁是一种自旋锁。正如名字所描述的，是一种基于队列\链表，通过将线程组织成一个队列的形式来一次进行上锁-处理-释放的同步方式。
在队列中，每个线程通过检测其前驱线程是否已完成(获得并释放锁)来判断是否轮到自己。每个线程在不同的存储单元自旋，从而降低cache一致性流，并提高临界区利用率。最后队列FIFO的特性保证了公平性。
1.2 CLH队列锁工作原理 一开始，CLHLock的队列只有一个尾部节点。然后多线程同时竞争上锁，两线程会调用原子的GetAndSet方法，获取尾部节点，并将此节点设置为自己的前驱节点作为，然后将自己线程转成节点插入队列的尾部。完成这些操作后，便进入自旋状态，直到前驱节点释放锁，即字段locked为false。
如下图，可以看作线程A、B同时竞争获取锁。线程A先插入到队尾并获得锁，线程B在线程A后面，即A是B的前驱节点。线程B会不断自旋，直到前驱结点，即线程A，的状态从locked变为unlock；而后线程B获得锁，线程A从队列中移除。
2、队列同步器(AQS) 2.1 AQS简述 AQS是基于CLHLock的一个拓展实现。其核心思想是：若被请求的资源空闲，则将当前请求资源的线程设为有限线程，并且将资源状态设为锁定。若被请求的资源被占用，则将暂时获得不到锁的线程加入队列中，并将线程挂起(阻塞)等待以及被唤醒时所分配。
AQS实现的CLHLock是一个双向队列。AQS将每条请求共享资源的线程封装成一个CLHLock队列的节点(Node)来实现所分配，并使用字段waitStatus来表示资源获得的状态。Node的类定义如下
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 static final class Node { // 表示线程取消等待，不竞争资源的获取 static final int CANCELLED = 1; // 表示获得资源锁了，对应线程无需挂起，需要唤醒 static final int SIGNAL = -1; // 用于表示线程节点在做条件等待 static final int CONDITION = -2; // 表示后续线程/节点在调用acquireShare()方法时可以无条件获得锁 static final int PROPAGATE = -3; // 初始化为0，而后或为上述4中状态值。 volatile int waitStatus; // 前驱节点 volatile Node prev; // 后继节点 volatile Node next; // 节点所代表的线程 volatile Thread thread; // 条件队列所用，表示同一条件等待队列中的下一个等待节点 Node nextWaiter; } 2.</description>
    </item>
    
    <item>
      <title>动态规划回顾</title>
      <link>http://localhost:1313/posts/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E5%9B%9E%E9%A1%BE/</link>
      <pubDate>Sun, 29 Aug 2021 16:09:24 +0800</pubDate>
      
      <guid>http://localhost:1313/posts/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E5%9B%9E%E9%A1%BE/</guid>
      <description>最近打算重新复习基础逻辑方面的知识，对于一些有趣或者复杂的知识点打算较为详细地记录下来，以便后面继续回顾。此文便是出于重新理解和整理动态规划的知识点而写作的。
什么是动态规划(Dynamic Programming)？动态规划是一种思想，一种运筹决策的方法。事实上许多能用动态规划解决的问题，同样可以使用回溯(backtracking)法解决。只是回溯法的时间复杂度高，而动态规划的时间复杂度低，即效率高，但相对的空间复杂度就可能会高一些。
简化的背包问题 一般理解动态规划，我喜欢从0-1背包问题出发：一个可承重$Wkg$的背包，现将$m$个重量不等的物品放入背包中，问在不超过背包所能装载重量的前提下，怎么放物品能让背包中物品的总重量最大。
回溯法 对于上述背包问题，背包的重量只是一个限制条件，我们需要进行操作的是物品。每个物品都有放入和不放入两种选择。回溯算法的方式就是通过穷举所有放入不超重的情况，记录当中最接近极限承重$Wkg$的结果。用代码表示逻辑如下：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 public static final int BAG_LOAD_BEARING = 100; // 背包的最大承重(kg) public static int getFloorWeight(int[] itemsWeight) { if (itemsWeight.length == 0) { return 0; } return calc(0, 0, itemsWeight); } private static int calc(int itemIndex, int bagCurWeight, int[] itemsWeight) { // 达到承重极限 或者 已经对所有物品做出选择后，返回当前背包重量 if (bagCurWeight == BAG_LOAD_BEARING || itemIndex == itemsWeight.</description>
    </item>
    
    <item>
      <title>分布式系统简述 Part 3</title>
      <link>http://localhost:1313/posts/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%AE%80%E8%BF%B0-part-3/</link>
      <pubDate>Wed, 26 May 2021 23:04:15 +0800</pubDate>
      
      <guid>http://localhost:1313/posts/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%AE%80%E8%BF%B0-part-3/</guid>
      <description>以下是笔者阅读学习Distributed systems for fun and profit所做的记录，大体算是笔者对书中内容的翻译。感兴趣的可以阅读原文~
5、Replication：弱一致性模型协议 在很长一段时间里，我们都是通过一个全局全序的方法来解决一致性问题，前面已经讨论了方法，它们都是通过非自然生成的全序顺序(以一种容错的方式)的形式来实现强一致性的。当然，强制实现有序的代价是昂贵的。特别是在大型的需要维持可用性(Avaliable)的互联网系统，这基本是行不通的。一个强制实现强一致性的系统会像一个单机系统一样运行，而不是分布式系统，这将会导致它在出现分区时可用性很糟糕。
更进一步的说，对于每次操作，多数节点都要保持联系——而且经常不是一次而是两次(正如在2PC上的讨论一样)。尤其是对于在地理上分布以为全球用户提供高性能的系统来说，这是十分令人痛苦。因此默认想单机系统一样运行可能是不可取的(Not Desirable)。
可能我们想要的系统是一个不需要编写复杂的用于协调的代码，然后也能返回一个“有用的”值。我们允许不同的副本相互之间有分歧——但可以保证执行效率和分区容灾——然后尝试找到一种方法来解决分歧。
最终一致性-Eventual Consistency就表达上述的想法：节点偶尔可以相互之间存在分歧，但是它们最终能够达到一致。最终一致性可分为以下两种形式：
Eventual consistency with probabilistic guarantees 在一段时间后(at some later point)，能够检测到写冲突，但是不能保证结果与正确的顺序执行的结果一致。也就是说，冲突更新有时会用旧值覆盖新值，导致一些异常情况的发生。 Eventual consistency with strong guarantees 此类型的系统能保证最终结果与正确顺序执行的结果一致(即不会产生异常结果)。如此，在没有任何协调操作的情况下，你可以创建副本，而这些副本可以以任意的形式通信、以任意的顺序接受更新命令，并且最终它们会达成一致的结果——只要他们接受到的信息是一样的。 CRDT&amp;rsquo;s (convergent replicated data types) 这是一种数据类型，在网络延迟、分区和信息重排序的情况下也能够得到相同结果。它们具有可证明的收敛性(Convergent)，但是可以实现为CRDT类型的数据类型是有限的。 CALM (consistency as logical monotonicity)猜想 此猜想(conjecture)是同一原理的不同表达：它把逻辑单调性(Logical Monotonicity)等同于收敛性(Convergent)。如果我们能推断得出某个系统是逻辑单调的，那么它可以无需协调即可安全运行。 5.1 Reconciling different operation orders 假设系统各节点因为某些原因无法通信，每个副本在分区时仍维持可用性，从一些客户端中接受读/写操作。而一段时间后，分区问题解决了，副本服务器相互交换信息。它们从不同的客户端接受不同的更新操作，并且相互之间存在分歧。因此需要进行调解——我们希望副本最终能达至一致的结果。
[Clients] - &amp;gt; [A] --- Partition --- [Clients] - &amp;gt; [B] --- Partition --- [Clients] - &amp;gt; [C] $\qquad\qquad\Downarrow$
[A] \\ --&amp;gt; [merge] [B] // | | [C] ----[merge]---&amp;gt; result 5.</description>
    </item>
    
    <item>
      <title>分布式系统简述 Part 2</title>
      <link>http://localhost:1313/posts/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%AE%80%E8%BF%B0-part-2/</link>
      <pubDate>Sat, 15 May 2021 20:17:49 +0800</pubDate>
      
      <guid>http://localhost:1313/posts/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%AE%80%E8%BF%B0-part-2/</guid>
      <description>以下是笔者阅读学习Distributed systems for fun and profit所做的记录，大体算是笔者对书中内容的翻译。感兴趣的可以阅读原文~
4、Replication 复制是一系列的通信问题——怎样的分配和通信方式能够达到我们想要的性能和有效性呢？在面对网络分区和同时多点故障时，我们如何保证容灾、持久以及无分歧呢？
分配和通信模式可以分成几个阶段：
请求(Request): 客户端发送一个请求到服务器端 同步(Sync): 复制的同步部分发生 响应(Respond): 返回一个响应给客户端 异步(Async): 复制的异步部分发生 上述模式切割基于这篇文章。需要注意，此模式任务中各个部分的消息交换依赖于特定算法，这里并没有给出(故意略过)。
4.1 同步复制(Synchronous replication) 同步复制也被称为Active或者Eager或者Push或者Pessimistic Replication。
同步复制有三个阶段：发出请求，然后调用复制的同步部分(这意味着客户端阻塞知道系统返回一个结果)。 假定同步部分，我们采取一个写N-to-N的方法：在响应返回给前端之前，系统的所有服务器已然知道此响应结果。而且如此，系统则不能允许任何一个服务器端故障，若故障，则客户端的写请求将无法进行。
4.2 异步复制(Asynchronous replication) 异步复制也被称为Passive或者Pull或者Lazy Replication。异步复制，顾名思义，是和同步复制相反的——master服务器立刻返回响应给客户端，而不会做任何与其他服务器的同步导致客户端阻塞。而且同样，其与其他服务器交流使用的通信模式也是根据不同的算法而不同。
假定采取的算法叫写1-to-N方法，从性能的角度上看，这样的系统是更快的，但是它的分配方式只能提供弱或者概率持久性的保证。如果没有出错，数据最终会被复制到所有N台机器上，然而如果唯一包含这个数据的服务器故障了，那么这个数据将会永远丢失。
使用写1-to-N方法，只要有一个节点能工作，系统就是可用的(至少在理论上是这样，实际上只有一个节点的话负载将会过高)。需要强调的一点是，被动复制(Passive Replication)不能保证系统中所有节点始终处于同一状态，如果你接受多位置(location)写且不要求这些节点同步，那么将会面临数据分歧的风险。
4.3 主流复制算法综述(An overview of major replication approaches) 复制算法的分类方式有很多种，除了同步vs异步的区分外，还可以分为：
避免数据分歧(single copy system): 此类算法能“behave like a single system”。特别是当出现分区失败时，系统保证只有一个拷贝是有效的(active)，即所有副本都是一直的，这也就是一致性/共识问题(consensus problem) 有数据分歧风险的(multi-master system) 如之前Consensus Problem所说的，要达到一致性/共识，需要满足Agreement、Integrity、Termination以及Validity。互斥(Mutual exclusion)，选举(leader election)，广播以及原子广播(atomic broadcast)都是更普遍的共识问题的例子。维护单一拷贝一致性的可复制系统需要以某种方式解决共识问题。
维护单一拷贝一致性的复制算法包括：
1n messages (asynchronous primary/backup) 2n messages (synchronous primary/backup) 4n messages (2-phase commit, Multi-Paxos) 6n messages (3-phase commit, Paxos with repeated leader election) 这些算法的容错性(fault tolerance)各不相同(例如 他们所容错的类型也不同)。以上是根据对应算法一次执行所需信息交换的次数区分的。下图改编自Ryan Barret at，展示了不同选择的不同方面： 上述图表中的：一致性(consistency)、延迟(lantency)、吞吐量(throughput)、数据丢失(data loss)以及故障转移(failover)等特性确实可以追溯会两种不同的复制方法：同步复制和异步复制——当同步时，将获得较差的性能但强的保障。另外当后面谈到分区容忍和延时容忍石，2PC和**仲裁系统(Quorum System)**之间吞吐量的差异将更加明显。</description>
    </item>
    
    <item>
      <title>分布式系统简述 Part 1</title>
      <link>http://localhost:1313/posts/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%AE%80%E8%BF%B0-part-1/</link>
      <pubDate>Tue, 11 May 2021 21:20:31 +0800</pubDate>
      
      <guid>http://localhost:1313/posts/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%AE%80%E8%BF%B0-part-1/</guid>
      <description>以下是笔者阅读学习Distributed systems for fun and profit所做的记录，大体算是笔者对书中内容的翻译。感兴趣的可以阅读原文~
2、系统模型理论 2.1 Consensus Problem 遵循以下几点，计算机/节点可以达到数据一致性：
统一性(Agreement): Every correct process must agree on the same value. 完整性(Integrity): Every correct process decides at most one value, and if it decides some value, then it must have been proposed by some process. 终止性(Termination): All processes eventually reach a decision. 有效性(Validity): If all correct processes propose the same value V, then all correct processes decide V 一致性/共识问题是所有商业分布式系统的核心。毕竟我们希望无需处理分散的结果(如节点的数据分歧/不同意)就可以获得一个可靠且高性能的分布式系统。并且解决一致性问题的同时，也解决一些相关的、更高级的问题(如 原子广播、原子提交等)。</description>
    </item>
    
    <item>
      <title>基础概率模型</title>
      <link>http://localhost:1313/posts/%E5%9F%BA%E7%A1%80%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8B/</link>
      <pubDate>Wed, 14 Apr 2021 22:17:24 +0800</pubDate>
      
      <guid>http://localhost:1313/posts/%E5%9F%BA%E7%A1%80%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8B/</guid>
      <description>1、贝叶斯定理 $P(x|y)$是条件概率，表示在$y$事件发生的情况下，$x$事件发生的概率。故，有$P(y,x)=P(x|y)\times P(y)$，表示同时发生$x,y$事件的概率=发生$y$事件的概率 乘以 在$y$事件发生的情况下发生$x$事件的概率。
当$x,y$事件相互独立时，就有贝叶斯公式如下： $$ P(x|y)\times P(y)=P(y,x)=P(x,y)=P(y|x)\times P(x) \\ \Downarrow \\ P(x|y)=\frac {P(y|x)\times P(x) }{ P(y) } $$ 其中$P(x)$称为先验概率，$P(y|x)$称为似然率(根据观测到的结果数据来预估模型的参数)，$P(y)$称为边缘概率。而最终得出的结果$P(x|y)$则称为后验概率。
2、朴素贝叶斯 朴素贝叶斯模型是一种分类模型——给出一个事物的一些特征，推断出该事物分别属于各类类别的概率。 $$ P(c|f_1,f_2,&amp;hellip;,f_i)=P(c|f_1)\times P(c|f_2)\times &amp;hellip; \times P(c|f_i) \\ \quad \\ \Rightarrow \frac{P(f_1|c)\times P(c) }{ P(f_1) }\times \frac{P(f_2|c)\times P(c) }{ P(f_2) }\times &amp;hellip;\times \frac{P(f_i|c)\times P(c) }{ P(f_i) } $$ 在进行贝叶斯公式的乘积计算时，常常会出现结果为0——某类别没有出现过某种特征，因此当前的似然率是0。一般会采取平滑(Smoothing)的方式处理——取一个比这个数据集里最小统计概率还要小的极小值，来代替零概率.
另外，在进行概率乘积计算的过程中，当特征很多时，乘积结果可能就小到计算机无法处理的地步，因此会采用一些数学方法进行转换(比如取log，将小数转化为绝对值大于1的负数)。
2.1 朴素贝叶斯分类过程： 准备数据：收集各类别事物的实例，归纳各类别事物的特征，并将其转化为计算机所能理解的数据。这种数据也被称为训练样本。 建立模型：用计算机统计类别事物、事物特征出现的先验概率，以及在某个分类下某种特征出现的条件概率。这个过程也被称为基于样本的训练。 分类新数据：对于一个新实例的特征数据，计算机根据已经建立的模型进行推导计算，得到该实例属于每个分类的概率，实现了分类的目的。这个过程也被称为预测。 2.2 与其他分类算法的比较 和KNN 最近邻相比，朴素贝叶斯需要更多的时间进行模型的训练，但是它在对新的数据进行分类预测的时候，通常效果更好、用时更短。 和决策树相比，朴素贝叶斯并不能提供一套易于人类理解的规则，但是它可以提供决策树通常无法支持的模糊分类（一个对象可以属于多个分类）。 和SVM 支持向量机相比，朴素贝叶斯无法直接支持连续值的输入。所以，在前面的案例中，我将连续值转化成了离散值，便于朴素贝叶斯进行处理。 3、马尔可夫(Markov)假设 3.1 链式法则 链式法则是概率论中一个常用法则。它使用一系列条件概念率和边缘概率，来推导联合概率。 $$ P(x_1,x_2,&amp;hellip;,x_n)=P(x_1)\times P(x_2|x_1)\times P(x_3|x_2,x_1)\times &amp;hellip;\times P(x_n|x_1,x_2,&amp;hellip;,x_{n-1}) $$</description>
    </item>
    
    <item>
      <title>从Shuffle到Sample——谈谈基本的随机算法</title>
      <link>http://localhost:1313/posts/%E4%BB%8Eshuffle%E5%88%B0sample%E8%B0%88%E8%B0%88%E5%9F%BA%E6%9C%AC%E7%9A%84%E9%9A%8F%E6%9C%BA%E7%AE%97%E6%B3%95/</link>
      <pubDate>Thu, 04 Feb 2021 12:40:47 +0800</pubDate>
      
      <guid>http://localhost:1313/posts/%E4%BB%8Eshuffle%E5%88%B0sample%E8%B0%88%E8%B0%88%E5%9F%BA%E6%9C%AC%E7%9A%84%E9%9A%8F%E6%9C%BA%E7%AE%97%E6%B3%95/</guid>
      <description>在笔者日常的工作中，常常会碰到类似这样的功能需求：从奖励池(含有$n$种奖励)中随机$m$种给用户，其中$n&amp;gt;m$。
p.s. 笔者的工作语言是Java，因此下面的代码都是以java的方式展现的。
1. 乱序(Shuffle) 最直接的做法可能就是，将该$n$种奖励随机打乱后，选取前$m$种给玩家，即：
1 2 3 4 5 List&amp;lt;Integer&amp;gt; randomPrizeIds(List&amp;lt;Integer&amp;gt; allPrizeIds, int num) { List&amp;lt;Integer&amp;gt; copy = new ArraysList(allPrizeIds); Collections.shuffle(copy); // 打乱列表元素原本的排列顺序 return copy.subList(0, num); } 但如此做法是否真的足够随机？这就取决于shuffle函数的具体实现逻辑。
1.1 等概率论证 要足够随机，则要求shuffle乱序过程中，每个元素重排到各个位置的概率是相等的。Collections.Shuffle使用的是Knuth-Durstenfeld Shuffle算法(或说Fisher–Yates Shuffle算法)，方法内部实现逻辑大致如下：
1 2 3 4 5 6 void shuffle(List&amp;lt;?&amp;gt; list, Random rnd) { int size = list.size(); for (int i = size; i &amp;gt; 1; i--) { swap(list, i - 1, rnd.nextInt(i)); } } 其乱序的实现方式其实就是：从后往前将列表中的元素置换到首位到当前位置的任意下标位置。假定一个包含n个元素的列表，那么从后往前：
对于n-1位置，每个可选择的元素置换到此位置的概率均为$\frac{1}{n}$，则留在到$[0,n-2]$下标位置的概率为$\frac{n-1}{n}$； 对于n-2位置，每个可选择的元素置换到此位置的概率均为$\frac{n-1}{n}\cdot\frac{1}{n-1}=\frac{1}{n}$，则留在到$[0,n-3]$区间的概率为$\frac{n-1}{n-2}$。 对于n-3位置，每个可选择的元素置换到此位置的概率均为$\frac{n-1}{n}\cdot\frac{n-2}{n-1}\cdot\frac{1}{n-2}=\frac{1}{n}$，则留在到$[0,n-4]$区间的概率为$\frac{n-1}{n-2}$。 &amp;hellip;&amp;hellip;.</description>
    </item>
    
  </channel>
</rss>
